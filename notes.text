build/Makefile

branches:
org.wisitoken          - working, used by o.e.a.s-4
org.wisitoken.stephe-1 - development

 current work
./Test/test_mckenzie_recover.adb:221:      Parser.Table.McKenzie.Check_Limit := 1; -- FIXME:

re2c supports case insensitive
    ' ' quotes; not compatible with elisp
    %keyword_case_insentive (no value)
    => convert " to ' in create_re2c

add line, comment info compute to re2c lexer
    in org.wisitoken.stephe-1
    re2c_simple, re2c_line_comment; subtype re2c_lexer is lexer range ...
    two classes of token; grammar and non-grammar
    both returned to parser
    both passed to semantic_state
    semantic_state stores non-grammar as list in preceding token
        wisitoken-token_line_comment
    otherwise parser ignores non-grammar

    ./wisi/wisi-gen_generate_utils.ads:174:      State       : Token_Cursor_State; --  FIXME: rename to Kind. use separate list for Non_Reporting
        in .wy - %non_grammar instead of %token

    ./wisitoken-lexer-re2c.adb:161:      --  FIXME: add C function to use token char pointer, length to fetch

Use indentation as hint?
    to solve missing 'end';
    at current edit point, if indent does not match:
        spawn parser,
        enter error recovery for just it,
        insert end ... to match, or fail.


improve mckenzie
    ./run_ada_lite_parser.exe ../test/ada_mode-recover_indent_3.adb --repeat_count 1000
    run_ada_parser.exe 0 1 -1 ../test/ada_mode-recover_indent_3.adb --repeat_count 10
        correct solution inserts 8 tokens, costs 8.
        ada_lite finds that after enqueue 4734, check  679;  0.000_231_979 seconds
        Full Ada finds that after enqueue 14164, check  1084; 0.010_793_146 seconds

    ./Test/test_mckenzie_recover.adb:442:      --  FIXME: recover finds "insert 'case; end'"; need another pattern

    ada_lite.profile
        top total time functions:
            wisitoken.token_arrays.finalize
            wisitoken.token_arrays.adjust
            wisitoken.parser.lr.mckenzie_recover.configuration.Finalize
            wisitoken.parser.lr.mckenzie_recover.":=" (for configuration, presumably)
            wisitoken.parser.lr.mckenzie_recover.config_heaps.exchange

    Derive token_array, add discriminant that sets initial size

    try Ada.Containers.Bounded_Vectors (first_terminal .. last_nonterminal) for token_arrays
        = 337 for Ada
        just in mckenzie first

    try lr1 ada_lite
        slow but tolerable wisi-generate time
            83 rules, 1 actions, 2612 states, 20615 table entries
            0 accept/reduce conflicts, 3 shift/reduce conflicts, 6 reduce/reduce conflicts
        gcc gives up; gnat1.exe: out of memory allocating 4072 bytes
            need to read table from file.

    config_queue:
        Fibonacci heap

    run mckenzie in parallel, take first success, kill other parsers
        for i in 1 .. cost_limit
            do each parser (i)
        end loop

        helps conflict resolve, but not ada_mode-recover_indent_3

    prune duplicate/higher cost configs?
        only needed for higher cost levels

new test cases:

    ----------
    target : constant string := "
        triggers face parse

    ----------
    Target : constant Unbounded_Wide_String := To_Unbounded_Wide_String "&ndash;";
        two errors close together?


    ----------
   procedure Process_Text_File (File_Name ; in String);
   is
   begin
   end Process_Text_File;
   noticeable delay: mckenzie (max cost 12) enqueue 138756, check  10931; fail
    correct solution is delete ';', insert ':' - cost 8, then later delete ;
    two errors too close together
    check_limit = 2 fixes it; set that in projects.text


----------

some tokens don't count towards check_limit, because we should always check the next token:
    END, DOT
    covers 'end if/loop/case/return/name', name.name

want to use Π in sal.gen_graphs (because reference does) but Aflex can't handle it
    so can't use run_ada_parser to debug indent/parse issues
    emacs lexer can't handle Π π either?

if hit enqueue_limit, use config that has highest check_token_count
    save in config

debug_kim_choe
    paper does _not_ actually build graph; searches it implicitly
        with a breadth-first search.
        it's not clear how it determines it has reached the goal
        not clear how to go back and insert terminals when find path
        we use a graph to store the multiple paths, since the goal is a token, not a state

    uses only reduction edges?
        that's what Definition 3.5 for Lookback, 3.14 for 'right context graph' says
        but there are states with no reduction edges

    uses kernels to compute edges
        in my output, some kernels have no gotos (added later)
        all kernel gotos are equivalent to table gotos/actions

    advantages over mckenzie:
        it can insert nonterms?
            not much help when most can be empty.

        it only follows least cost edge
            so does mckenzie

        more efficient storage managment?
            totally up to me

debug_kim_choe.adb
    use sal.gen_graph
        write test_graphs in sal, with example from CLRS 22.2
        c:/Projects/org.stephe_leake.sal/build/Makefile
        add nonterm weights = shortest terminal count (+ 1 for empty?)

    generate graph from action_for, goto_for

Emacs_ada does not need descriptor.image?

next change in wisi/test/*.good_parse_table
    don't output mckenzie if default

Merge cursor, parser_node_access

replace wisitoken.token.list with token_array
    or not; changes generate?
    ditto production.list

rename mckenzie to dpa_explore?
    dpa = deterministic parsing automata (McKenzie)
        = Deterministic Pushdown Automata (Wikipedia, Grune)

    aflex uses "dfa" deterministic finite automata
    grune also uses 'deterministic fs automata' (Finite State)

    includes special rules

better syntax error handling
    new algorithm 0:
        Grune 326 Kim, Choe 2001
        Definition 3.5 Lookback is just reduce
        faster because it searches grammar graph including nonterminals, not dpa with only terminals
        just implement the algorithms, see if that makes it clearer.
            appears to be just Dijkstra
                https://en.m.wikipedia.org/wiki/Dijkstra%27s_algorithm#Specialized_variants
                    change costs to non-negative integers
                not clear where the difference is
            not clear how to compute S(A) for nonterminals?
                Fischer Mauney 1989 ? no
                fischer, dion, mauney 1979?
                or dion, fischer, 1978? not in google scholar
                or it's "just obvious"; terminal_sequences_1

        Annotate grammar to eliminate cycles for least-cost search?

        Precompute list of forced paths to shift terminal - shortens path search?
            terminal_sequences_2 below

    new algorithm 1:
        if error symbol is in a terminal sequence:
                need fast lookup; use linear search for now
            find first terminal in sequence that is in follow (current state), or equiv
            insert that sequence subset, do McKenzie

        process grammar to generate shortest terminal sequences for each nonterm
            same as Grune 326 S(A)

            that does _not_ insert 'elsif' into 'if_statement'
                which is why we need a full graph search?

            also produce second list with optional nonterms, to find sequence for elsif?
                not repeating nonterms
                how do we decide to keep 'elsif', but not all statement variants?

            terminal_sequences_1.adb

        move param into .wy

        move terminal_sequences.adb into wisi-*

    new algorithm 2:
        adjust mckenzie costs to include terminal sequences
        include current_token in cost function
            cost of "if then | elsif" = 0.0

        include current state and current token in cost function:
            cost of "125 | then | elsif" = 0
            125 implied by trying 'then' without preceding 'if'

    t_one RUN_ARGS=1
        Error_5
            deleted 'if then'
            fixed with hardcoded 'if then else endif' sequence; need general solution
                doing kim, choe 2001 dpa graph search

    search dpa backwards from elsif; insert 'if then'
        same result as Grune 326 graph search; do that?

        terminal_sequences_2.adb
        states that shift ELSIF:
            168 if_statement <= IF expression_opt THEN sequence_of_statements_opt ^ elsif_statement_list
            187 elsif_statement_list <= elsif_statement_list ^ elsif_statement_list
            need list/tree/hash of states that shift ID, sorted on ID

        'goto state 187' is in 168 on elsif_statement_list

        'goto state 168' is in
            159 if_statement <= IF expression_opt THEN ^ sequence_of_statements_opt * on sequence_of_statements_opt
            need list/tree/hash of states that goto state, sorted on goto state

        'goto state 159' is in 128 'if_statement <=' on shift THEN => insert THEN
            ditto

        'goto state 128' is in 100 'if_statement <= IF ^ ' on expression_opt
            ditto

        'goto state 100' is in many, on 'shift IF' => insert IF, terminate

        search all productions in 'declarations', 'statements'?
            start with final terminal, work backward to first

    cache recover for subsequent parse

    test lr1 vs lalr tables
        ada_lite.lr1_parse_table
        10 times the states, table entries

    then to elisp parser?

    or Emacs module parser
        elisp lexer supports utf-8, other encodings; tick/char_literal

    Leaves some sections unindented - OK if not user line (not typical editing case).
        not uncached; if indent is not computed, cache is 0
        If indent cache 0, use previous line?
        see how it works in practice

include actual token count in nonterminal pop cost?
    requires cumulative token count on parser stack

Panic mode is supposed to skip input to ';', then pop states - grune 16.6.1

speed up
    stack compare
        override "=" to start comparison at stack top; most likely to be different

    replace look on ID calling action_for with iterate action list for state

    use tasks for multi-processor?

    compress parser table via default reduce?

    set initial capacity on stacks

    check_reduce does not need to copy stack
        just keep track of current top separately, pointer into reduced top

    during parallel error recovery, if one parser finds a solution, limit cost of others to solution cost + 2?
        doesn't help if first parser fails

automatically augment grammar with empty productions
    anything not a keyword is optional
    may create too many conflicts

wisi-generate accept two output languages
    a lot is shared
    only need ada_output, but it doesn't hurt

wisi-generate lr1 way too slow for Ada
    time lalr generating Ada
    time lr1 generating ada_lite (1634 states, tens of seconds)
    time lr1 generating Ada to first 1000 states; increase as it gets better

    implement profile, get data

    don't iterate on non-reporting

    lookahead list vs boolean array:
        time opentoken vs fasttoken
        or old fasttoken

    closure needs:
        fast access to all productions that have dot_id as the LHS
            => array (nonterminal) of list of prod

        fast access to First (beta) => array (nonterminal) of list of terminal

        use multiple threads?

    lr1_goto_transitions needs:
        fast closure
        cache?

        use optimizations from lalr_goto_transitions?

    LR1_Item_Sets needs:
        fast goto_transitions (state, token)
            => use cache; invalidate when ?

        fast find (set, states)
            => Store states in red/black tree sorted on concat LHS/dot position
                or hash table on that key
                    keeps changing, not clear if it's worth finding a perfect hash table
                each node has a list of states that differ only in lookahead
                => one for LALR

            c:/org.stephe-leake.misc/source/rb_tree_V0_1
                bounded, not generic, but proved by Spark
                at least use key_trees-test.adb Tree_Invariant for test
                use to generate test cases?

            c:/org.stephe-leake.sal/source/sal-gen_red_black.ads
                write tests

        no 'free'; don't allocate item on heap until we know we need it

    lalr_goto_transitions needs:
        fast find prod, dot in goto_set
            null result is common
            small set; linear search of list sorted on lhs

        fast access to all productions where:
            (Dot_ID = Nonterminal.ID (Prod.LHS) or First (Dot_ID)(Nonterminal.ID (Prod.LHS))) and
                       (RHS.first /= Null_Iterator and then ID (RHS.first) = Symbol)
            => array (nonterminal) of list of productions, sorted on rhs.first

    lalr_kernels needs:
        same as lr1_item_sets

    lalr calls closure on each kernel more than once!
        save the closure the first time?

    need more warm-fuzzy
    command line option
    dots for "adding state n", n every 100
    dots for "lookaheads state n", n every 100?
    dynamically monitor how long things take, keep dot time period constant
        everything slows down as more states added

integrate with emacs module

ada_grammar.adb very slow to compile
    eliminating all but one action subprograms; not much help

    read tables from text file?
        action subprogram names as integer index into array of subprogram pointers.

change dragon examples
    lexer.regexp; should be easy

    lexer.aflex/wisi-generate
        need support for different actions
        move code from tokens to actions
        change .wy action syntax to require {} (for elisp as well)
        use Ada code in actions; reference New_Token, Source, To_ID
            or whatever than changes to
        add Ada output language to wisi-generate
            just copy text between {} to action function
                add constant space prefix to each line; source must meet style check

change wisi tests to use Ada code?

 Quex notes
giving up on Quex because
    - it failed in my first test (did not lex eof properly)
    - it behaved differently under the debugger
      - meaning it's using uninitalized vars
      - it's very hard to debug
    - it's not clear it solves the tick/char literal issue

use Quex lexer (recommended by AdaCore/langkit)
    https://sourceforge.net/projects/quex/
    windows installer in d:/Archive/Emacs
    installed to d:/Apps/quex-0.67.5
    example lexer : d:/Apps/quex/quex-0.67.5/demo/C/000/Makefile
        edited Makefile so it runs
        needs iconv
        d:/msys64/mingw32/include/iconv.h
        ./mingw32/lib/libiconv.a
        hand-written main in lexer-wchar.c
        hand-written main in d:/Apps/quex/quex-0.67.5/demo/C/example.c

        use mingw32 compiler
            use mingw32-make
            creates lexer.exe
            lexer.exe example.txt works
        use gnat C
            cp d:/msys64/mingw32/include/iconv.h d:/Apps/GNAT-gpl_2016/include/
            cp d:/msys64/mingw32/lib/libiconv.a  d:/Apps/GNAT-gpl_2016/lib/gcc/i686-pc-mingw32/4.9.4/
            works!

    look in libadalang for Ada bindings to quex output
        libpgrlang-lexer.adb
        uses GNATCOLL.Iconv to decode buffer; quex handles 32 bit chars
        quex_interface.c, h; provides next_token
        quex_lexer.h, .c generated by quex
        copied to quex/*

    hand transform build/ada_lite.l => quex/ada_lite.qx
        cd quex
        d:/Apps/quex/quex-0.67.5/quex-exe.py --language C -i ada_lite.qx -o ada_lite
        generated:
            ada_lite-configuration.h - lots of #defines
            ada_lite-token.h         - access to token data?
            ada_lite-token_ids.h     - token id constants
            ada_lite.c               - state machine for lexer
            ada_lite.h               - ? lexer API? ; same as quex_lexer.h (except version diffs)

        copy example.c to run_ada_lite_lexer.c

        gcc -I $QUEX_PATH ada_lite.c run_ada_lexer.c -liconv -o run_ada_lexer.exe
        ./run_ada_lexer.exe ../test/ada_mode-recover_indent_3.adb
            works!

        use -DQUEX_OPTION_ASSERTS_DISABLED for speed, -DQUEX_OPTION_ASSERTS_WARNING_MESSAGE_DISABLED otherwise
            C compiler args

    add Quex to wisi lexer options, use instead of Aflex
        parsing!
        terminates with "bad lexatom" instead of eoi
            reading past end of input
            not seeing 0

        behaves differently under debugger!
0: 12: NUMBER_LITERAL : shift and goto state 3
Assertion failed!

Program: c:\Projects\org.wisitoken.stephe-1\build\case_expression_run.exe
File: C:\Projects\org.wisitoken.stephe-1\build\case_expression_lexer.c:430

    how to enable __quex_debug?




        need a utf8 input file





        *.qx take_text uses Quex internal data names to compute offset; changed with version
            deleted for now

            we know address of start of buffer! lexer.buffer!
                do pointer arithmetic in ada, via address_to_access_conversion or something

            needed for Lexeme
                or provide C function to return string; also problematic
            check latest AdaCore source for fix
                not there; not definitive, they could have a version check
                install new quex version
                send them email
            post on Quex mailing list



        verify quex version in rules.make

        review quex token_id mapping

        do dvc-status

        add quex to gpr source path,  so gpr_query finds it
            also requires c compiler option

    see if it has options/rules/hooks to fix wisi/test/character_literal.wy
        how does libadalang handle this?
        last_token_id?


 aflex
    /Projects/aflex/build/Makefile
    /Projects/aflex/aflex.adb
    source from http://sourceforge.net/projects/p2ada/

    better error messages; gnu syntax

    regenerate aflex.l
        start with flex.l?

# end of file
