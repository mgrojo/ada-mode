build/Makefile

branches:
org.wisitoken          - working, used by o.e.a.s-2
org.wisitoken.stephe-1 - translate elisp actions to Ada, used by o.e.a.s-4

(dvc-state-multiple
'((xmtn . "c:/Projects/org.stephe_leake.makerules")
  (xmtn . "c:/Projects/org.stephe_leake.sal.stephe-1")
  (xmtn . "c:/Projects/org.wisitoken.stephe-1")))

 current work
move token_line_comment into wisitoken.semantic_state.token; no need for dispatching/classwide token type
    augmented_token_array can be definite

delete Index from Semantic_Action

Use correction cost to pick parser in terminate duplicate

update NEWS.text

Can compute max tokens length for actions from grammar - use fixed array size
    may cause generic explosion

Fixed size stack speed mckenzie?

need case-insensitive compare in match-names
    UTF-8 version
    ASCII bytes do not appear in UTF-8 unless they are valid, so to_lower (Character) is safe

if full parse fails, go back to successful error recover and find more expensive solutions
    save full config_heap after successful error recover

reorganize into three package hierarchies:
    wisitoken.parse - parser runtime
    wisitoken.generate - represent grammar as production list, generate parse table
    wisitoken.wisi - translate.wy files into production list, source code

    semantic_state.recover_data should be mckenzie configuration; no need for pointer


do multi-cpu parsing?
    won't help as much in absence of errors
    errors are when speed is noticeable


cache recover for subsequent parse?

still losing memory?
    possibly Augmented_Token_Array
        deallocation thru root class type?

    run_ada_lite_parser wisi/test/ada_lite.input with gnatmem
        no change in leaks from repeat count 1 to repeat count 2

    run ada on gnatcoll-xref
        allocation root 1 increased by (- 167.88 165.12) = 2.76 kilobytes

    run ada_mode_wisi_parse on test/gnatcoll-xref.adb
        (setq ada-process-parse-exec "c:/Projects/org.emacs.ada-mode.stephe-2/exec_pro/ada_mode_wisi_parse.exe")
        (setq wisi-process--alist nil)
        (setq ada-process-parse-exec "ada_mode_wisi_parse")
        doesn't create gmem.out; using wrong exec!
            need to rerun ada-mode, not just parse
            still wrong! using cached parser wisi-process--alist on label Ada
            still no gmem.out

        running wisi-parse-buffer and watching task manager shows no memory increase. sigh.
        watch memory while editing other files
        wait for compute indent in ada

improve mckenzie
    focus on real use cases that are slow; document in ada-mode/test

    ./Test/test_mckenzie_recover.adb:442:      --  FIXME: recover finds "insert 'case; end'"; need another pattern

    exec_pro/ada_lite_run.exe 10 c:/Projects/org.emacs.ada-mode.stephe-2/test/slow_recover_1.adb
         1: mckenzie enqueue 540, check  69; succeed : 8, (18 : IDENTIFIER, )|OR|/THEN, IF, IDENTIFIER/
         1: mckenzie enqueue 1373, check  181; succeed : 8, (196 : END, )|IDENTIFIER|/IF, SEMICOLON, END, IF, SEMICOLON, END/
        ada_lite-slow_recover_1.profile
            top total time functions:
  0.00      0.09     0.00   231856     0.00     0.00  wisitoken__parser__lr__parser_stacks__element_arrays__finalize__2
  0.00      0.09     0.00   231855     0.00     0.00  wisitoken__parser__lr__parser_stacks__stack_typeDF__2

    try lr1 ada_lite
        slow but tolerable wisi-generate time
            83 rules, 1 actions, 2612 states, 20615 table entries
            0 accept/reduce conflicts, 3 shift/reduce conflicts, 6 reduce/reduce conflicts
        gcc gives up; gnat1.exe: out of memory allocating 4072 bytes
            need to read table from file.

    include current state and current token in cost function:
        cost of "125 | then | elsif" = 0
        125 implied by trying 'then' without preceding 'if'

    config_queue:
        Fibonacci heap

    for each state, pre-compute shortest list of tokens (term/nonterm) to finish each nonterm
        test/terminal_sequences_1.adb
        If any contain next token, queue that fragment.
        use case: start typing a statement, hit enter
            => error correction finishes statement with minimum token count.
            but this case is not slow now;
                'if a = 5 then' => queue 90

    prune duplicate/higher cost configs?
        only needed for higher cost levels

    cost for pop empty nonterm should be zero
        need byte_range in parser
            could get it from semantic_state, unless pending.
        wait til we find a test case that needs it


new test cases:

    ----------
    target : constant string := "
        triggers face parse

    ----------
    Target : constant Unbounded_Wide_String := To_Unbounded_Wide_String "&ndash;";
        two errors close together?


    ----------
   procedure Process_Text_File (File_Name ; in String);
   is
   begin
   end Process_Text_File;
   noticeable delay: mckenzie (max cost 12) enqueue 138756, check  10931; fail
    correct solution is delete ';', insert ':' - cost 8, then later delete ;
    two errors too close together
    check_limit = 2 fixes it; set that in projects.text


----------

some tokens don't count towards check_limit, because we should always check the next token:
    END, DOT
    covers 'end if/loop/case/return/name', name.name

want to use Π in sal.gen_graphs (because reference does) but Aflex can't handle it
    so can't use run_ada_parser to debug indent/parse issues
    emacs lexer can't handle Π π either?

if hit enqueue_limit, use config that has highest check_token_count
    save in config

debug_kim_choe
    paper does _not_ actually build graph; searches it implicitly
        with a breadth-first search.
        it's not clear how it determines it has reached the goal
        not clear how to go back and insert terminals when find path
        we use a graph to store the multiple paths, since the goal is a token, not a state

    uses only reduction edges?
        that's what Definition 3.5 for Lookback, 3.14 for 'right context graph' says
        but there are states with no reduction edges

    uses kernels to compute edges
        in my output, some kernels have no gotos (added later)
        all kernel gotos are equivalent to table gotos/actions

    advantages over mckenzie:
        it can insert nonterms?
            not much help when most can be empty.

        it only follows least cost edge
            so does mckenzie

        more efficient storage managment?
            totally up to me

debug_kim_choe.adb
    use sal.gen_graph
        write test_graphs in sal, with example from CLRS 22.2
        c:/Projects/org.stephe_leake.sal/build/Makefile
        add nonterm weights = shortest terminal count (+ 1 for empty?)

    generate graph from action_for, goto_for

Emacs_ada does not need descriptor.image?

next change in wisi/test/*.good_parse_table
    don't output mckenzie if default

Merge cursor, parser_node_access

replace wisitoken.token.list with token_array
    or not; changes generate?
    ditto production.list

rename mckenzie to dpa_explore?
    dpa = deterministic parsing automata (McKenzie)
        = Deterministic Pushdown Automata (Wikipedia, Grune)

    aflex uses "dfa" deterministic finite automata
    grune also uses 'deterministic fs automata' (Finite State)

    includes special rules


other mckenzie stuff
    search dpa backwards from elsif; insert 'if then'
        same result as Grune 326 graph search; do that?

        terminal_sequences_2.adb
        states that shift ELSIF:
            168 if_statement <= IF expression_opt THEN sequence_of_statements_opt ^ elsif_statement_list
            187 elsif_statement_list <= elsif_statement_list ^ elsif_statement_list
            need list/tree/hash of states that shift ID, sorted on ID

        'goto state 187' is in 168 on elsif_statement_list

        'goto state 168' is in
            159 if_statement <= IF expression_opt THEN ^ sequence_of_statements_opt * on sequence_of_statements_opt
            need list/tree/hash of states that goto state, sorted on goto state

        'goto state 159' is in 128 'if_statement <=' on shift THEN => insert THEN
            ditto

        'goto state 128' is in 100 'if_statement <= IF ^ ' on expression_opt
            ditto

        'goto state 100' is in many, on 'shift IF' => insert IF, terminate

        search all productions in 'declarations', 'statements'?
            start with final terminal, work backward to first

    test lr1 vs lalr tables
        ada_lite.lr1_parse_table
        10 times the states, table entries

    include actual token count in nonterminal pop cost?
        requires cumulative token count on parser stack

speed up
    profile parsing gnatcoll-xref

    stack compare
        override "=" to start comparison at stack top; most likely to be different

    replace look on ID calling action_for with iterate action list for state

    use tasks for multi-processor?

    compress parser table via default reduce?

    set initial capacity on stacks

    check_reduce does not need to copy stack
        just keep track of current top separately, pointer into reduced top

    during parallel error recovery, if one parser finds a solution, limit cost of others to solution cost + 2?
        doesn't help if first parser fails

automatically augment grammar with empty productions
    anything not a keyword is optional
    may create too many conflicts

wisi-generate accept two output languages
    a lot is shared
    only need ada_output, but it doesn't hurt

wisi-generate lr1 way too slow for Ada
    time lalr generating Ada
    time lr1 generating ada_lite (1634 states, tens of seconds)
    time lr1 generating Ada to first 1000 states; increase as it gets better

    implement profile, get data

    don't iterate on non-reporting

    lookahead list vs boolean array:
        time opentoken vs fasttoken
        or old fasttoken

    closure needs:
        fast access to all productions that have dot_id as the LHS
            => array (nonterminal) of list of prod

        fast access to First (beta) => array (nonterminal) of list of terminal

        use multiple threads?

    lr1_goto_transitions needs:
        fast closure
        cache?

        use optimizations from lalr_goto_transitions?

    LR1_Item_Sets needs:
        fast goto_transitions (state, token)
            => use cache; invalidate when ?

        fast find (set, states)
            => Store states in red/black tree sorted on concat LHS/dot position
                or hash table on that key
                    keeps changing, not clear if it's worth finding a perfect hash table
                each node has a list of states that differ only in lookahead
                => one for LALR

            c:/org.stephe-leake.misc/source/rb_tree_V0_1
                bounded, not generic, but proved by Spark
                at least use key_trees-test.adb Tree_Invariant for test
                use to generate test cases?

            c:/org.stephe-leake.sal/source/sal-gen_red_black.ads
                write tests

        no 'free'; don't allocate item on heap until we know we need it

    lalr_goto_transitions needs:
        fast find prod, dot in goto_set
            null result is common
            small set; linear search of list sorted on lhs

        fast access to all productions where:
            (Dot_ID = Nonterminal.ID (Prod.LHS) or First (Dot_ID)(Nonterminal.ID (Prod.LHS))) and
                       (RHS.first /= Null_Iterator and then ID (RHS.first) = Symbol)
            => array (nonterminal) of list of productions, sorted on rhs.first

    lalr_kernels needs:
        same as lr1_item_sets

    lalr calls closure on each kernel more than once!
        save the closure the first time?

    need more warm-fuzzy
    command line option
    dots for "adding state n", n every 100
    dots for "lookaheads state n", n every 100?
    dynamically monitor how long things take, keep dot time period constant
        everything slows down as more states added

integrate with emacs module

ada_grammar.adb very slow to compile
    eliminating all but one action subprograms; not much help

    build parse table without actions in one file, add actions in another
        -> smaller files

    read tables from text file?
        action subprogram names as integer index into array of subprogram pointers.

change dragon examples
    lexer.regexp; should be easy

    lexer.aflex/wisi-generate
        need support for different actions
        move code from tokens to actions
        change .wy action syntax to require {} (for elisp as well)
        use Ada code in actions; reference New_Token, Source, To_ID
            or whatever than changes to
        add Ada output language to wisi-generate
            just copy text between {} to action function
                add constant space prefix to each line; source must meet style check

change wisi tests to use Ada code?

 Quex notes
giving up on Quex because
    - it failed in my first test (did not lex eof properly)
    - it behaved differently under the debugger
      - meaning it's using uninitalized vars
      - it's very hard to debug
    - it's not clear it solves the tick/char literal issue

use Quex lexer (recommended by AdaCore/langkit)
    https://sourceforge.net/projects/quex/
    windows installer in d:/Archive/Emacs
    installed to d:/Apps/quex-0.67.5
    example lexer : d:/Apps/quex/quex-0.67.5/demo/C/000/Makefile
        edited Makefile so it runs
        needs iconv
        d:/msys64/mingw32/include/iconv.h
        ./mingw32/lib/libiconv.a
        hand-written main in lexer-wchar.c
        hand-written main in d:/Apps/quex/quex-0.67.5/demo/C/example.c

        use mingw32 compiler
            use mingw32-make
            creates lexer.exe
            lexer.exe example.txt works
        use gnat C
            cp d:/msys64/mingw32/include/iconv.h d:/Apps/GNAT-gpl_2016/include/
            cp d:/msys64/mingw32/lib/libiconv.a  d:/Apps/GNAT-gpl_2016/lib/gcc/i686-pc-mingw32/4.9.4/
            works!

    look in libadalang for Ada bindings to quex output
        libpgrlang-lexer.adb
        uses GNATCOLL.Iconv to decode buffer; quex handles 32 bit chars
        quex_interface.c, h; provides next_token
        quex_lexer.h, .c generated by quex
        copied to quex/*

    hand transform build/ada_lite.l => quex/ada_lite.qx
        cd quex
        d:/Apps/quex/quex-0.67.5/quex-exe.py --language C -i ada_lite.qx -o ada_lite
        generated:
            ada_lite-configuration.h - lots of #defines
            ada_lite-token.h         - access to token data?
            ada_lite-token_ids.h     - token id constants
            ada_lite.c               - state machine for lexer
            ada_lite.h               - ? lexer API? ; same as quex_lexer.h (except version diffs)

        copy example.c to run_ada_lite_lexer.c

        gcc -I $QUEX_PATH ada_lite.c run_ada_lexer.c -liconv -o run_ada_lexer.exe
        ./run_ada_lexer.exe ../test/ada_mode-recover_indent_3.adb
            works!

        use -DQUEX_OPTION_ASSERTS_DISABLED for speed, -DQUEX_OPTION_ASSERTS_WARNING_MESSAGE_DISABLED otherwise
            C compiler args

    add Quex to wisi lexer options, use instead of Aflex
        parsing!
        terminates with "bad lexatom" instead of eoi
            reading past end of input
            not seeing 0

        behaves differently under debugger!
0: 12: NUMBER_LITERAL : shift and goto state 3
Assertion failed!

Program: c:\Projects\org.wisitoken.stephe-1\build\case_expression_run.exe
File: C:\Projects\org.wisitoken.stephe-1\build\case_expression_lexer.c:430

    how to enable __quex_debug?




        need a utf8 input file





        *.qx take_text uses Quex internal data names to compute offset; changed with version
            deleted for now

            we know address of start of buffer! lexer.buffer!
                do pointer arithmetic in ada, via address_to_access_conversion or something

            needed for Lexeme
                or provide C function to return string; also problematic
            check latest AdaCore source for fix
                not there; not definitive, they could have a version check
                install new quex version
                send them email
            post on Quex mailing list



        verify quex version in rules.make

        review quex token_id mapping

        do dvc-status

        add quex to gpr source path,  so gpr_query finds it
            also requires c compiler option

    see if it has options/rules/hooks to fix wisi/test/character_literal.wy
        how does libadalang handle this?
        last_token_id?


 aflex
    /Projects/aflex/build/Makefile
    /Projects/aflex/aflex.adb
    source from http://sourceforge.net/projects/p2ada/

    better error messages; gnu syntax

    regenerate aflex.l
        start with flex.l?

# end of file
