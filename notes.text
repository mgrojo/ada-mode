build/Makefile

branches:
org.wisitoken          - working, used by o.e.a.s-4
org.wisitoken.stephe-1 - development

 current work
need 'if' in .wy for elisp/re2c diffs
    %keyword shared
    %token <punctuation> shared
        except TICK vs TICK_1, _2, _3
        actually not a problem; elisp will only every see TICK_1

    whitespace ignored by elisp
    line_comment ignored by elisp
    symbol, string-* value ignored by wisi-make-elisp-lexer; should be ignored in wisi-output_elisp_common

leaking memory
    ada_mode_wisi_parse.exe memory grows with each parse
        mostly during parses that take a long time
            mckenzie, or lots of parsers?

    two_mem runs gnatmem on run_ada_lite_parser ada_mode-recover_indent_3
        only suspicious result is:
Allocation Root # 3
-------------------
 Number of non freed allocations    : 797
 Final Water Mark (non freed mem)   : 17.17 Kilobytes
 High Water Mark                    : 1.85 Megabytes
 Backtrace                          :
   s-pooglo.adb:0 ??

    add gnat.debug_pool to sal-gen_min_heap
        debug_pools.dump_gnatmem outputs the same information as gnatmem; nothing new!
        add print_info_stdout; lots of confusing numbers, not helpful

    run on a similar file with no errors: ada_mode-recover_indent_3_fixed.adb
        suspicious result not changed much; 795, everything else the same
        => not mckenzie

    parsers used:
        broken: 0 .. 3
        fixed : same

    does it scale with repeat?
        goes up by 2 with each repeat

    double code length
        gnatmem_test2.adb
        uses parsers 0 .. 5
        795 allocations

    run on full ada, on code that causes memory growth in task manager

can't parse wisi/test/gnatcoll-xref.adb:
    run_ada_parser.exe wisi/test/gnatcoll-xref.adb  --verbosity 1 > gnatcoll-xref.parse
    error on character literal

    error not reported properly:
        line numbers wrong, State.Errors empty
            because recover not called? need recover(fail)?
 486: 189: EQUAL : reduce 1 tokens to simple_expression
(simple_expression 2344:13) <= ((term_list 2344:13))
 ... goto state 376
 486: 376: EQUAL : shift and goto state 337
 486: 337: TICK : ERROR
 486: expecting: ABS, LEFT_PAREN, NEW, NOT, NULL, MINUS, PLUS, NUMERIC_LITERAL, IDENTIFIER, STRING_LITERAL, CHARACTER_LITERAL

 McKenzie error recovery

parser 486:
mckenzie (max cost 12) enqueue 45638, check  3426; fail
recover: fail


wisi/test/gnatcoll-xref.adb wisitoken-parser-lr-parser.adb:588


put back mckenzie-enable in wisi-process-parse
    so can disable for memory tests, and for really bad syntax (like C code that needs to be wrapped in Indent_Line)

use re2c lexer generator
    add re2c option to report errors in gnu format
        clone from sourceforge; c:/Projects/re2c-code-git

    propagate to o.w, use in o.e.a.s-4

leaking memory
    see org.wisitoken notes
    if Linker_Options works in .gpr, post on comp.lang.ada "link errors with GNAT GPL 2016 and gprof"
    test/gnatmem_test_3.adb
        task manager memory usage +0.1 MB per parse
        < 0.1 MB per parse when errors fixed

    test/gnatmem_test_4.adb
        task manager memory usage +0.7 MB per parse

    test/gnatmem_test_5.adb
        task manager memory usage > +100 MB per parse
            even with mckenzie_cost_limit = 2
            must be due to dying parsers?

    report memory use during parse
        https://msdn.microsoft.com/en-us/library/windows/desktop/ms682050(v=vs.85).aspx
        ada.tasking?
        ada.processor_info?

token_cursor iterator definition
    use rosen trick to store writeable info in the iterator object (not the cursor object)
    both are specific to one loop.
    or not; all of state is just a fancy pointer, which belongs in Cursor, and should be copied.

delete Wisi.Gen_Generate_Utils gen param to_token_out_image; should be token_id'image?
    see FIXME: in wisi-gen_output_ada_common.ads

review all FIXME:

Use indentation as hint?
    to solve missing 'end';
    at current edit point, if indent does not match:
        spawn parser,
        enter error recovery for just it,
        insert end ... to match, or fail.


improve mckenzie
    ./run_ada_lite_parser.exe ../test/ada_mode-recover_indent_3.adb --repeat_count 1000
    run_ada_parser.exe 0 1 -1 ../test/ada_mode-recover_indent_3.adb --repeat_count 10
        correct solution inserts 8 tokens, costs 8.
        ada_lite finds that after enqueue 4734, check  679;  0.000_231_979 seconds
        Full Ada finds that after enqueue 14164, check  1084; 0.010_793_146 seconds

    run_ada_parser.exe 0 1 -1 ../wisi/test/gnatcoll-xref.adb --repeat_count 10
        requires better lexer

    ada_lite.profile
        top total time functions:
            wisitoken.token_arrays.finalize
            wisitoken.token_arrays.adjust
            wisitoken.parser.lr.mckenzie_recover.configuration.Finalize
            wisitoken.parser.lr.mckenzie_recover.":=" (for configuration, presumably)
            wisitoken.parser.lr.mckenzie_recover.config_heaps.exchange

    try Ada.Containers.Bounded_Vectors (first_terminal .. last_nonterminal) for token_arrays
        = 337 for Ada
        just in mckenzie first

    try lr1 ada_lite
        slow but tolerable wisi-generate time
            83 rules, 1 actions, 2612 states, 20615 table entries
            0 accept/reduce conflicts, 3 shift/reduce conflicts, 6 reduce/reduce conflicts
        gcc gives up; gnat1.exe: out of memory allocating 4072 bytes
            need to read table from file.

    config_queue:
        Fibonacci heap

    run mckenzie in parallel, take first success, kill other parsers
        for i in 1 .. cost_limit
            do each parser (i)
        end loop

        helps conflict resolve, but not ada_mode-recover_indent_3

new test cases:

    ----------
    target : constant string := "
        triggers face parse

    ----------
    Target : constant Unbounded_Wide_String := To_Unbounded_Wide_String "&ndash;";
        two errors close together?


    ----------
   procedure Process_Text_File (File_Name ; in String);
   is
   begin
   end Process_Text_File;
   noticeable delay: mckenzie (max cost 12) enqueue 138756, check  10931; fail
    correct solution is delete ';', insert ':' - cost 8, then later delete ;
    two errors too close together
    check_limit = 2 fixes it; set that in projects.text


----------

some tokens don't count towards check_limit, because we should always check the next token:
    END, DOT
    covers 'end if/loop/case/return/name', name.name

want to use Π in sal.gen_graphs (because reference does) but Aflex can't handle it
    so can't use run_ada_parser to debug indent/parse issues
    emacs lexer can't handle Π π either?

if hit enqueue_limit, use config that has highest check_token_count
    save in config

debug_kim_choe
    paper does _not_ actually build graph; searches it implicitly
        with a breadth-first search.
        it's not clear how it determines it has reached the goal
        not clear how to go back and insert terminals when find path
        we use a graph to store the multiple paths, since the goal is a token, not a state

    uses only reduction edges?
        that's what Definition 3.5 for Lookback, 3.14 for 'right context graph' says
        but there are states with no reduction edges

    uses kernels to compute edges
        in my output, some kernels have no gotos (added later)
        all kernel gotos are equivalent to table gotos/actions

    advantages over mckenzie:
        it can insert nonterms?
            not much help when most can be empty.

        it only follows least cost edge
            so does mckenzie

        more efficient storage managment?
            totally up to me

debug_kim_choe.adb
    use sal.gen_graph
        write test_graphs in sal, with example from CLRS 22.2
        c:/Projects/org.stephe_leake.sal/build/Makefile
        add nonterm weights = shortest terminal count (+ 1 for empty?)

    generate graph from action_for, goto_for

Emacs_ada does not need descriptor.image?

next change in wisi/test/*.good_parse_table
    don't output mckenzie if default

Merge cursor, parser_node_access

replace wisitoken.token.list with token_array
    or not; changes generate?
    ditto production.list

rename mckenzie to dpa_explore?
    dpa = deterministic parsing automata (McKenzie)
        = Deterministic Pushdown Automata (Wikipedia, Grune)

    aflex uses "dfa" deterministic finite automata
    grune also uses 'deterministic fs automata' (Finite State)

    includes special rules

better syntax error handling
    new algorithm 0:
        Grune 326 Kim, Choe 2001
        Definition 3.5 Lookback is just reduce
        faster because it searches grammar graph including nonterminals, not dpa with only terminals
        just implement the algorithms, see if that makes it clearer.
            appears to be just Dijkstra
                https://en.m.wikipedia.org/wiki/Dijkstra%27s_algorithm#Specialized_variants
                    change costs to non-negative integers
                not clear where the difference is
            not clear how to compute S(A) for nonterminals?
                Fischer Mauney 1989 ? no
                fischer, dion, mauney 1979?
                or dion, fischer, 1978? not in google scholar
                or it's "just obvious"; terminal_sequences_1

        Annotate grammar to eliminate cycles for least-cost search?

        Precompute list of forced paths to shift terminal - shortens path search?
            terminal_sequences_2 below

    new algorithm 1:
        if error symbol is in a terminal sequence:
                need fast lookup; use linear search for now
            find first terminal in sequence that is in follow (current state), or equiv
            insert that sequence subset, do McKenzie

        process grammar to generate shortest terminal sequences for each nonterm
            same as Grune 326 S(A)

            that does _not_ insert 'elsif' into 'if_statement'
                which is why we need a full graph search?

            also produce second list with optional nonterms, to find sequence for elsif?
                not repeating nonterms
                how do we decide to keep 'elsif', but not all statement variants?

            terminal_sequences_1.adb

        move param into .wy

        move terminal_sequences.adb into wisi-*

    new algorithm 2:
        adjust mckenzie costs to include terminal sequences
        include current_token in cost function
            cost of "if then | elsif" = 0.0

        include current state and current token in cost function:
            cost of "125 | then | elsif" = 0
            125 implied by trying 'then' without preceding 'if'

    t_one RUN_ARGS=1
        Error_5
            deleted 'if then'
            fixed with hardcoded 'if then else endif' sequence; need general solution
                doing kim, choe 2001 dpa graph search

    search dpa backwards from elsif; insert 'if then'
        same result as Grune 326 graph search; do that?

        terminal_sequences_2.adb
        states that shift ELSIF:
            168 if_statement <= IF expression_opt THEN sequence_of_statements_opt ^ elsif_statement_list
            187 elsif_statement_list <= elsif_statement_list ^ elsif_statement_list
            need list/tree/hash of states that shift ID, sorted on ID

        'goto state 187' is in 168 on elsif_statement_list

        'goto state 168' is in
            159 if_statement <= IF expression_opt THEN ^ sequence_of_statements_opt * on sequence_of_statements_opt
            need list/tree/hash of states that goto state, sorted on goto state

        'goto state 159' is in 128 'if_statement <=' on shift THEN => insert THEN
            ditto

        'goto state 128' is in 100 'if_statement <= IF ^ ' on expression_opt
            ditto

        'goto state 100' is in many, on 'shift IF' => insert IF, terminate

        search all productions in 'declarations', 'statements'?
            start with final terminal, work backward to first

    cache recover for subsequent parse

    test lr1 vs lalr tables
        ada_lite.lr1_parse_table
        10 times the states, table entries

    then to elisp parser?

    or Emacs module parser
        elisp lexer supports utf-8, other encodings; tick/char_literal

    Leaves some sections unindented - OK if not user line (not typical editing case).
        not uncached; if indent is not computed, cache is 0
        If indent cache 0, use previous line?
        see how it works in practice

include actual token count in nonterminal pop cost?
    requires cumulative token count on parser stack

Panic mode is supposed to skip input to ';', then pop states - grune 16.6.1

speed up
    stack compare
        override "=" to start comparison at stack top; most likely to be different

    replace look on ID calling action_for with iterate action list for state

    use tasks for multi-processor?

    compress parser table via default reduce?

    set initial capacity on stacks

    check_reduce does not need to copy stack
        just keep track of current top separately, pointer into reduced top

    during parallel error recovery, if one parser finds a solution, limit cost of others to solution cost + 2?
        doesn't help if first parser fails

automatically augment grammar with empty productions
    anything not a keyword is optional
    may create too many conflicts

wisi-generate accept two output languages
    a lot is shared
    only need ada_output, but it doesn't hurt

wisi-generate lr1 way too slow for Ada
    time lalr generating Ada
    time lr1 generating ada_lite (1634 states, tens of seconds)
    time lr1 generating Ada to first 1000 states; increase as it gets better

    implement profile, get data

    don't iterate on non-reporting

    lookahead list vs boolean array:
        time opentoken vs fasttoken
        or old fasttoken

    closure needs:
        fast access to all productions that have dot_id as the LHS
            => array (nonterminal) of list of prod

        fast access to First (beta) => array (nonterminal) of list of terminal

        use multiple threads?

    lr1_goto_transitions needs:
        fast closure
        cache?

        use optimizations from lalr_goto_transitions?

    LR1_Item_Sets needs:
        fast goto_transitions (state, token)
            => use cache; invalidate when ?

        fast find (set, states)
            => Store states in red/black tree sorted on concat LHS/dot position
                or hash table on that key
                    keeps changing, not clear if it's worth finding a perfect hash table
                each node has a list of states that differ only in lookahead
                => one for LALR

            c:/org.stephe-leake.misc/source/rb_tree_V0_1
                bounded, not generic, but proved by Spark
                at least use key_trees-test.adb Tree_Invariant for test
                use to generate test cases?

            c:/org.stephe-leake.sal/source/sal-gen_red_black.ads
                write tests

        no 'free'; don't allocate item on heap until we know we need it

    lalr_goto_transitions needs:
        fast find prod, dot in goto_set
            null result is common
            small set; linear search of list sorted on lhs

        fast access to all productions where:
            (Dot_ID = Nonterminal.ID (Prod.LHS) or First (Dot_ID)(Nonterminal.ID (Prod.LHS))) and
                       (RHS.first /= Null_Iterator and then ID (RHS.first) = Symbol)
            => array (nonterminal) of list of productions, sorted on rhs.first

    lalr_kernels needs:
        same as lr1_item_sets

    lalr calls closure on each kernel more than once!
        save the closure the first time?

    need more warm-fuzzy
    command line option
    dots for "adding state n", n every 100
    dots for "lookaheads state n", n every 100?
    dynamically monitor how long things take, keep dot time period constant
        everything slows down as more states added

integrate with emacs module
    split out ada_grammar from ada_grammar_process, _module

some .wy in wisi_wy_test.adb, some in rules.make
    be more consistent
        easier to update in rules.make

ada_grammar.adb very slow to compile
    eliminating all but one action subprograms; not much help

    read tables from text file?
        action subprogram names as integer index into array of subprogram pointers.

need better lexer for wisitoken
    handle tick character literal
    handle utf-8

    lexer used by libadalang?

need case insensitive flag in .wy
    use for keywords
    pass to lexers

Test case gathering - wisi fallback email first use each day.

need to_token_wy_name
    for reporting conflicts

Ada lexer
    number:
        add _
        add leading integer to distinguish 16 from identifier

    identifier: add leading letter

review FIXME
    ./fasttoken-parser-lalr-parser.adb:346:            --  FIXME: free everything
        add Controlled to stuff

change dragon examples
    lexer.regexp; should be easy

    lexer.aflex/wisi-generate
        need support for different actions
        move code from tokens to actions
        change .wy action syntax to require {} (for elisp as well)
        use Ada code in actions; reference New_Token, Source, To_ID
            or whatever than changes to
        add Ada output language to wisi-generate
            just copy text between {} to action function
                add constant space prefix to each line; source must meet style check

change wisi tests to use Ada code?

 Quex notes
giving up on Quex because
    - it failed in my first test (did not lex eof properly)
    - it behaved differently under the debugger
      - meaning it's using uninitalized vars
      - it's very hard to debug
    - it's not clear it solves the tick/char literal issue

use Quex lexer (recommended by AdaCore/langkit)
    https://sourceforge.net/projects/quex/
    windows installer in d:/Archive/Emacs
    installed to d:/Apps/quex-0.67.5
    example lexer : d:/Apps/quex/quex-0.67.5/demo/C/000/Makefile
        edited Makefile so it runs
        needs iconv
        d:/msys64/mingw32/include/iconv.h
        ./mingw32/lib/libiconv.a
        hand-written main in lexer-wchar.c
        hand-written main in d:/Apps/quex/quex-0.67.5/demo/C/example.c

        use mingw32 compiler
            use mingw32-make
            creates lexer.exe
            lexer.exe example.txt works
        use gnat C
            cp d:/msys64/mingw32/include/iconv.h d:/Apps/GNAT-gpl_2016/include/
            cp d:/msys64/mingw32/lib/libiconv.a  d:/Apps/GNAT-gpl_2016/lib/gcc/i686-pc-mingw32/4.9.4/
            works!

    look in libadalang for Ada bindings to quex output
        libpgrlang-lexer.adb
        uses GNATCOLL.Iconv to decode buffer; quex handles 32 bit chars
        quex_interface.c, h; provides next_token
        quex_lexer.h, .c generated by quex
        copied to quex/*

    hand transform build/ada_lite.l => quex/ada_lite.qx
        cd quex
        d:/Apps/quex/quex-0.67.5/quex-exe.py --language C -i ada_lite.qx -o ada_lite
        generated:
            ada_lite-configuration.h - lots of #defines
            ada_lite-token.h         - access to token data?
            ada_lite-token_ids.h     - token id constants
            ada_lite.c               - state machine for lexer
            ada_lite.h               - ? lexer API? ; same as quex_lexer.h (except version diffs)

        copy example.c to run_ada_lite_lexer.c

        gcc -I $QUEX_PATH ada_lite.c run_ada_lexer.c -liconv -o run_ada_lexer.exe
        ./run_ada_lexer.exe ../test/ada_mode-recover_indent_3.adb
            works!

        use -DQUEX_OPTION_ASSERTS_DISABLED for speed, -DQUEX_OPTION_ASSERTS_WARNING_MESSAGE_DISABLED otherwise
            C compiler args

    add Quex to wisi lexer options, use instead of Aflex
        parsing!
        terminates with "bad lexatom" instead of eoi
            reading past end of input
            not seeing 0

        behaves differently under debugger!
0: 12: NUMBER_LITERAL : shift and goto state 3
Assertion failed!

Program: c:\Projects\org.wisitoken.stephe-1\build\case_expression_run.exe
File: C:\Projects\org.wisitoken.stephe-1\build\case_expression_lexer.c:430

    how to enable __quex_debug?




        need a utf8 input file





        *.qx take_text uses Quex internal data names to compute offset; changed with version
            deleted for now

            we know address of start of buffer! lexer.buffer!
                do pointer arithmetic in ada, via address_to_access_conversion or something

            needed for Lexeme
                or provide C function to return string; also problematic
            check latest AdaCore source for fix
                not there; not definitive, they could have a version check
                install new quex version
                send them email
            post on Quex mailing list



        verify quex version in rules.make

        review quex token_id mapping

        do dvc-status

        add quex to gpr source path,  so gpr_query finds it
            also requires c compiler option

    see if it has options/rules/hooks to fix wisi/test/character_literal.wy
        how does libadalang handle this?
        last_token_id?


 aflex
    /Projects/aflex/build/Makefile
    /Projects/aflex/aflex.adb
    source from http://sourceforge.net/projects/p2ada/

    better error messages; gnu syntax

    regenerate aflex.l
        start with flex.l?

# end of file
