build/Makefile

 current work
fix McKenzie with parallel parsers
        force a conflict
        don't terminate any if all fail
        _dont_ exit recover with first success; all parsers may succeed
   procedure Check
     (Label    : in String;
      Computed : in Error_Data;
      Expected : in Error_Data)
   is
   end Check;

       function To_Token_Array (Item : in Plain_Token_Array) return Token_Arrays.

better syntax error handling
    new algorithm 1:
        if error symbol is in a terminal sequence:
                need fast lookup; use linear search for now
            find first terminal in sequence that is in follow (current state), or equiv
            insert that sequence subset, do McKenzie

        process grammar to generate shortest terminal sequences for each nonterm
            same as Grune 326 S(A), but that does not require empty nonterms
                it recurses into all nonterms, finding shortest string

            that does _not_ insert 'elsif' into 'if_statement'
                which is why we need a full graph search?

            also produce second list with optional nonterms, to find sequence for elsif?
                not repeating nonterms
                how do we decide to keep 'elsif', but not all statement variants?

            terminal_sequences_1.adb

        move param into .wy

        move terminal_sequences.adb into wisi-*

    new algorithm 2:
        adjust mckenzie costs to include terminal sequences
        include current_token in cost function
            cost of "if then | elsif" = 0.0

        include current state and current token in cost function:
            cost of "125 | then | elsif" = 0
            125 implied by trying 'then' without preceding 'if'

    t_one RUN_ARGS=1
        Error_5
            deleted 'if then'
            fixed with hardcoded 'if then else endif' sequence; need general solution
                doing kim, choe 2001 dpa graph search

        new test cases:
procedure Debug
is begin
   procedure Put_Top_10
   is
   begin
   end Put_Top_10;

   begin
   end Debug;
            Added 'begin' at end, intending to delete first 'begin'

            Mckenzie inserts "end;" after first 'begin', exceeds 200 at last 'begin'
                needs to insert 'procedure IDENTIFIER is'
                at enqueue_limit 400, that is inserted, with a cost of 11, but doesn't check beyond 9
                at enqueue_limit 800, that is is checked, but fails
                    fix that and time it
                    works for ada_lite (sigh)
                    attach debugger works
                    looking for config.cost = 11, config.inserted.elements.all = (51, 103, 35)
                    fails because it's in state 133 generic_instantiation!?

 2 stack:  33 : subprogram_body,  14 : compilation_unit_list,  0 :
 2: 33: BEGIN : ERROR

enqueue: 133, 130, 41, 26, 14, 0,  BEGIN (PROCEDURE, IDENTIFIER, IS, ) null 1.10000E+01
26 includes "subprogram_body <= " _after_ "generic_instantiation <= overriding_indicator_opt ^ PROCEDURE name IS"
41 has :
generic_instantiation <= overriding_indicator_opt PROCEDURE ^ name IS
procedure_specification <= PROCEDURE ^ name parameter_profile_opt, IS
    on IDENTIFIER goto state 47
    on name goto state 130
47 is name <= IDENTIFIER ^, on IS reduce to 'name'
130 has :
generic_instantiation <= overriding_indicator_opt PROCEDURE name ^ IS
procedure_specification <= PROCEDURE name ^ parameter_profile_opt, IS
    on IS => shift and goto state 133,
             reduce 0 tokens to parameter_profile_opt

    we need the second; queue another config; why didn't it?
        restore config on second loop iteration

            first 'begin' is already pushed on stack, so McKenzie
            doesn't consider deleting it (and neither does Kim_Choe),
            but that would be the best solution.

        'if **'

    Panic mode is supposed to skip input to ';', then pop states - grune 16.6.1

    search dpa backwards from elsif; insert 'if then'
        same result as Grune 326 graph search; do that?

        terminal_sequences_2.adb
        states that shift ELSIF:
            168 if_statement <= IF expression_opt THEN sequence_of_statements_opt ^ elsif_statement_list
            187 elsif_statement_list <= elsif_statement_list ^ elsif_statement_list
            need list/tree/hash of states that shift ID, sorted on ID

        'goto state 187' is in 168 on elsif_statement_list

        'goto state 168' is in
            159 if_statement <= IF expression_opt THEN ^ sequence_of_statements_opt * on sequence_of_statements_opt
            need list/tree/hash of states that goto state, sorted on goto state

        'goto state 159' is in 128 'if_statement <=' on shift THEN => insert THEN
            ditto

        'goto state 128' is in 100 'if_statement <= IF ^ ' on expression_opt
            ditto

        'goto state 100' is in many, on 'shift IF' => insert IF, terminate

        search all productions in 'declarations', 'statements'?
            start with final terminal, work backward to first

    Grune 326 Kim, Choe 2001
        branch wisitoken.stephe_1
        Definition 3.5 Lookback is just reduce
        don't understand why RC(u) works
        just implement the algorithms, see if that makes it clearer.
            not clear how to compute S(A) for nonterminals?
                Fischer Mauney 1989 ? no
                fischer, dion, mauney 1979?
                or dion, fischer, 1978? not in google scholar
                or it's "just obvious"; extend terminal_sequences_1

    rename mckenzie to dpa_explore?
        dpa = deterministic parsing automata (McKenzie)
            = Deterministic Pushdown Automata (Wikipedia, Grune)

        aflex uses "dfa" deterministic finite automata
        grune also uses 'deterministic fs automata' (Finite State)

        includes special rules

        use Grune 326 to find candidates

    cache recover for subsequent parse

    test lr1 vs lalr tables
        ada_lite.lr1_parse_table
        10 times the states, table entries

    then to elisp parser?

    or Emacs module parser
        elisp lexer supports utf-8, other encodings; tick/char_literal

    Leaves some sections unindented - OK if not user line (not typical editing case).
        not uncached; if indent is not computed, cache is 0
        If indent cache 0, use previous line?
        see how it works in practice

    speed up
        replace look on ID calling action_for with iterate action list for state

        use tasks for multi-processor?

        compress parser table via default reduce?

        set initial capacity on stacks

        check_reduce does not need to copy stack
            just keep track of current top separately, pointer into reduced top

automatically augment grammar with empty productions
    anything not a keyword is optional
    may create too many conflicts

wisi-generate accept two output languages
    a lot is shared
    only need ada_output, but it doesn't hurt

move output_ada_emacs, output_elisp to ada-mode source tree?
    extendable dispatch?

wisi-generate lr1 way too slow for Ada
    time lalr generating Ada
    time lr1 generating ada_lite (1634 states, tens of seconds)
    time lr1 generating Ada to first 1000 states; increase as it gets better

    implement profile, get data

    don't iterate on non-reporting

    lookahead list vs boolean array:
        time opentoken vs fasttoken
        or old fasttoken

    closure needs:
        fast access to all productions that have dot_id as the LHS
            => array (nonterminal) of list of prod

        fast access to First (beta) => array (nonterminal) of list of terminal

        use multiple threads?

    lr1_goto_transitions needs:
        fast closure
        cache?

        use optimizations from lalr_goto_transitions?

    LR1_Item_Sets needs:
        fast goto_transitions (state, token)
            => use cache; invalidate when ?

        fast find (set, states)
            => Store states in red/black tree sorted on concat LHS/dot position
                or hash table on that key
                    keeps changing, not clear if it's worth finding a perfect hash table
                each node has a list of states that differ only in lookahead
                => one for LALR

            c:/org.stephe-leake.misc/source/rb_tree_V0_1
                bounded, not generic, but proved by Spark
                at least use key_trees-test.adb Tree_Invariant for test
                use to generate test cases?

            c:/org.stephe-leake.sal/source/sal-gen_red_black.ads
                write tests

        no 'free'; don't allocate item on heap until we know we need it

    lalr_goto_transitions needs:
        fast find prod, dot in goto_set
            null result is common
            small set; linear search of list sorted on lhs

        fast access to all productions where:
            (Dot_ID = Nonterminal.ID (Prod.LHS) or First (Dot_ID)(Nonterminal.ID (Prod.LHS))) and
                       (RHS.first /= Null_Iterator and then ID (RHS.first) = Symbol)
            => array (nonterminal) of list of productions, sorted on rhs.first

    lalr_kernels needs:
        same as lr1_item_sets

    need more warm-fuzzy
    command line option
    dots for "adding state n", n every 100
    dots for "lookaheads state n", n every 100?
    dynamically monitor how long things take, keep dot time period constant
        everything slows down as more states added

    rename to opentoken7
        _not_ "fast" :(
        or speed it up

integrate with emacs module
    split out ada_grammar from ada_grammar_process, _module

some .wy in wisi_wy_test.adb, some in rules.make
    be more consistent
        easier to update in rules.make

ada_grammar.adb very slow to compile
    eliminating all but one action subprograms; not much help

    read state transitions from text file?
    -> .exe is independent of language

need better lexer for wisitoken
    handle tick character literal
    handle utf-8

    lexer used by libadalang?

need case insensitive flag in .wy
    use for keywords
    pass to lexers

Test case gathering - wisi fallback email first use each day.

lalr calls closure on each kernel more than once!
    save the closure the first time?

need to_token_wy_name
    for reporting conflicts

Ada lexer
    number:
        add _
        add leading integer to distinguish 16 from identifier

    identifier: add leading letter

review FIXME
    ./fasttoken-parser-lalr-parser.adb:346:            --  FIXME: free everything
        add Controlled to stuff

change dragon examples
    lexer.regexp; should be easy

    lexer.aflex/wisi-generate
        need support for different actions
        move code from tokens to actions
        change .wy action syntax to require {} (for elisp as well)
        use Ada code in actions; reference New_Token, Source, To_ID
            or whatever than changes to
        add Ada output language to wisi-generate
            just copy text between {} to action function
                add constant space prefix to each line; source must meet style check

change wisi tests to use Ada code?

 aflex
    /Projects/aflex/build/Makefile
    /Projects/aflex/aflex.adb
    source from http://sourceforge.net/projects/p2ada/

    better error messages; gnu syntax

    regenerate aflex.l
        start with flex.l?

# end of file
