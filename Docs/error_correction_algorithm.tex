%% compilation command: latex -file-line-error -interaction=nonstopmode <file>
\documentclass{article}
\usepackage{algorithm2e}[longend noline]
\title{Robust error correction in a generalized LR parser}
\author{Stephen Leake}
\begin{document}
\section{Abstract}

\section{Introduction}
Emacs Ada mode has used an LR parser to support indentation, syntax
highlighting, and navigation since 2013 (\cite{Emacs Ada mode news}).
However, the parser did not provide error correction, so the
indentation was often confusing when the syntax was incorrect, as it
usually is in an interactive editing environment. This motivated the
search for error correction algorithms.

\cite{Grune 2008} provides a thorough overview of error correction in
LR and LL parsers. Of those algorithms presented, \cite{McKenzie 1995}
provides the foundation for the current work.

The McKenzie algorithm works by exploring the parse table (or
Deterministic Parsing Automata (DPA) as \cite{McKenzie 1995} calls it)
at the error point, finding tokens to insert. It also tries deleting
tokens following the error point. Each possible solution, together
with the parse stack at the error point, forms a
\textit{configuration}. Each configuration also has a cost, determined
by what tokens are inserted and deleted. At each step in the
algorithm, new configurations are generated from the current error
point. Then the minimum cost configuration is checked to see if it
succeeds; if not, more configurations are generated.

There are several situations where the McKenzie algorithm can take a
long time, or is inefficient.

For example, consider this Ada code:
\begin{verbatim}
procedure Example_01
is begin
   Msg : constant String;
begin
   Put_Line (Msg);
end;
\end{verbatim}

There is an extra \verb|begin| immediately after \verb|is| (a common
occurance while editing code). However, the error is not detected
until \verb|:|, which can only occur in declarations, not statements.

To fix this, the McKenzie algorithm must insert
\verb|; end; begin <identifier>|, or delete
\verb|constant String; begin| and then insert \verb|;|. A much better
solution would be to ``push back'' \verb|Msg begin|, and then delete
\verb|begin|.

A harder problem is when there are several missing ``end''s, because
the user is typing a nested statement:
\begin{verbatim}
begin
   if A then
      B;
      if C then
         loop
           Do_Something;
end;
\end{verbatim}

Here we are missing several tokens: \verb|end loop; end if; end if;|.
McKenzie will eventually find the solution that inserts all of these,
but along the way it will try inserting every possible statement as
well, wasting a lot of time. Our new algorithm quickly finds the
minimal number of tokens to insert to complete the trailing statement
in situations like this.

This article introduces several new operations for the core McKenzie
algorithm to try at the error point, and adapts the algorithm to work
with a generalized parser.

%% copy initial parts of mckenzie to define 'config' etc?

\section{Extensions to McKenzie}

\subsection{push\_back}
\verb|push_back| pops the top parse stack item, and moves the input
stream pointer back to the first terminal contained by that item. We
call the point in the input stream at which insert and delete is done
the ``edit point''; it may not be an error point. \verb|push_back|
moves the edit point.

\subsection{undo\_reduce}
\verb|undo_reduce| undoes the reduce that produced the top stack item
(which must be a nonterminal), replacing the top stack item by the
sequence of stack items just before the reduction, without
moving the edit point. This requires a syntax tree that records the
shifts and reductions done during the parse. The input pointer is not
moved. This operation serves two purposes;

1) it allows a subsequenct \verb|push_back| to push back fewer tokens.

2) it allows token insertions that would otherwise be forbidden by the
grammar.

To illustrate the second point, consider:
\begin{verbatim}
procedure Example_2
is
   I : Integer;
begin
   procedure Put_Top_10
   is begin
   ...
   end Put_Top_10;
begin
end Example_2;
\end{verbatim}
There is an extra \verb|begin| after
\verb|I : Integer|. The error is detected at \verb|procedure|; at that point,
the parse stack looks like (top is to the left):
\begin{verbatim}
245 : BEGIN, 208 : declarative_part, 159 : IS, 36 : subprogram_specification, 0 :
\end{verbatim}
Here the numbers label the states, terminals are in uppercase,
nonterminals in lowercase.

Fixing the parse error starts by \verb|push_back BEGIN, delete BEGIN|,
leaving \verb|declarative_part| on top of the stack. \verb|PROCEDURE|
is the next token, which is illegal in state 208; it starts a
declaration, but we've already ``closed'' the declaration section by
reducing to \verb|declarative_part|. We could do
\verb|push_back declarative_part|, but that moves the edit point to
before \verb|I|, where there is no error and nothing helpful to insert
or delete. \verb|undo_reduce declaration_part| leaves the stack as:

\begin{verbatim}
137 : declarations, 159 : IS, 36 : subprogram_specification, 0 :
\end{verbatim}
and now \verb|PROCEDURE| is legal.

\subsection{Try\_Insert\_Quote}
Missing string quotes also cause problems for the McKenzie algorithm.
Consider the Ada fragment:
\begin{verbatim}
A : String := Now is the time for all good men";
\end{verbatim}
There is a missing quote before \verb|Now|. In Ada, strings cannot
cross newline, so the lexer inserts a virtual quote just before the
existing one. So the parser sees a list of identifiers followed by a
string literal. The McKenzie algorithm would have to delete all the
identifiers one by one, with a cost for each.

The \verb|Try_Insert_Quote| operation attempts to find a better
place to insert the string quote, depending on the relative placement
of the unbalanced quote and the parse error.

\begin{itemize}
\item If the parse error is at the unbalanced quote, assume the unbalanced
quote is the intended closing quote, and insert the opening quote one
non-empty token before it. Example:
\begin{verbatim}
   A := "for all" & good ";
\end{verbatim}
We are in the process of splitting a string across lines; we just
added \verb|" &|, but are missing the \verb|"| before \verb|good|.
This solution inserts that missing quote.

\item If the parse error is after the unbalanced quote, assume the unbalanced
quote is the intended opening quote, and insert the closing quote at
the line end. Example:
\begin{verbatim}
   A := "for all" & "good ;
\end{verbatim}
The missing \verb|"| should be after \verb|good|.
This solution inserts that missing quote.

\item If the parse error is before the unbalanced quote, assume the unbalanced
quote is the intended closing quote, and insert the opening quote:

\begin{itemize}
\item before the error token. Example:
\begin{verbatim}
   A := for all good";
\end{verbatim}
The missing \verb|"| should be before \verb|for|. The parse error is at \verb|all|;
this solution inserts the missing quote before \verb|all|, which is
almost right.

\item one non-empty token before the unbalanced quote. Same example,
  but this inserts the \verb|"| before \verb|all|, which is correct.

\item If there is a string literal on the parse stack,
assume the closing quote of that string literal is new (or extra),
and extend the string literal to the unbalanced quote. Example:
\begin{verbatim}
   A := "for all" good";
\end{verbatim}
The \verb|"| after \verb|all| is extra. The parse error is at \verb|good|;
this solution in effect deletes the extra quote.

Note that the search for a string literal on the parse stack must take
into account nonterminals that may contain a string literal. This
requires the syntax tree mentioned in connection with
\verb|undo_reduce| above. The set of nonterminals that may contain a
string literal is provided as a function call written by the grammar
author; it is not computed from the grammar because it should not
include higher level nonterminals that are not likely to be contained
in a string; for Ada, it stops at expression.
\end{itemize}
\end{itemize}

Since the lexer recognizes string literals, we cannot actually insert
an unbalanced string quote; we actually delete all tokens between the
inserted quote and the unbalanced quote, which matches what the lexer
would have returned. This is still much better than the original
McKenzie algorithm, because we do all the deletions in one step, with
one low cost.

\subsection{Minimal\_Complete}
Consider this code (mentioned in the introduction):

\begin{figure}[ht]
\begin{verbatim}
begin
   if A then
      B;
      if C then
         loop
           Do_Something;
end;
\end{verbatim}
\caption{}
\label{ex:min_com_if_if_loop}
\end{figure}
The best error correction is to provide all of the missing ``ends''.
We can do this quickly be augmenting the parse table with a
\verb|Minimal_Complete_Action|, giving the terminal token to insert in
the state that reports the error.

When parsing this code, an error is detected at the final \verb|;|;
the parser is expecting \verb|end loop;|. The production being parsed
at that point is:
\begin{verbatim}
loop_statement <= LOOP sequence_of_statements END ^ LOOP identifier_opt SEMICOLON
\end{verbatim}
where the carrot (\verb|^|) shows the parse point. In this
case, it is easy to see that \verb|Minimal_Complete_Action| must be
\verb|LOOP|. Similarly, after parsing \verb|LOOP|, \verb|Minimal_Complete_Action|
is \verb|identifier_opt|, and then \verb|;|. After that,
we will be completing the inner \verb|if then| statement, and then the
outer \verb|if then| statement. At that point, the existing
\verb|end ;| is legal.

Section \ref{minimal-complete-compute} gives the algorithm for
computing the \verb|Minimal_Complete| tokens; here we describe how
they are used in error correction.

The check to see if the original error token is now legal must be
performed after each nonterminal is completed. Rather than trying to
encode the notion of ``completing a nonterminal'', we do the check
after inserting each token; this means that \verb|Minimal_Complete|
inserts at most one token for each cycle of the underlying McKenzie
algorithm.

In order to prefer the \verb|Minimal_Complete| solution over others,
we give it a negative cost. In all examples in this paper, the default
insert and delete cost is 4, delete \verb|BEGIN| is cost 1, delete
\verb|END|, \verb|;| are cost 2. With \verb|Minimal_Complete| cost 0,
-1, or -2, no solution for figure \ref{ex:min_com_if_if_loop} is
found, with an enqueue limit of 120,000. With \verb|Minimal_Complete|
cost -3, the desired solution is found with cost 9, after enqueueing
6804 configurations and checking 1051.

As usual, there is a trade off here; setting the magnitude high
encourages \verb|Minimal_Complete| over other solutions, but sometimes
other solutions would be better. For example, consider:
\begin{figure}[ht]
\begin{verbatim}
for I in 1 to Result_Length loop
end loop;
\end{verbatim}
\label{ex:min_com_loop_to}
\end{figure}
Here \verb|to| should be \verb|..| (this is an actual error the author
typed late one night). The error is detected at \verb|to|, so the
desired solution is \verb|delete IDENTIFIER, insert ..|. With the
\verb|Minimal_Complete| cost set to 0, this solution is found, along
with 19 other solutions with the same cost; a few of these change the
code to:

\begin{verbatim}
in to.Result_Length loop
in 1 .. to*Result_Length loop
in 1 .. to/Result_Length loop
\end{verbatim}

Finding these takes a relatively long time; 1273 configurations
were enqueued and 218 checked.

Setting \verb|Minimal_Complete| cost to -1 finds similar solutions,
but more quickly (341 enqueued, 56 checked); \verb|insert ..| is done
by \verb|Minimal_Complete|, so it is cheaper, and more expensive
solutions are not checked.

Setting \verb|Minimal_Complete| cost to -3 (as required for
example \ref{ex:min_com_if_if_loop}) finds one cost 3 solution very
quickly (67 enqueued, 10 checked); it changes the code to:
\begin{figure}[ht]
\begin{verbatim}
for I in 1 .. to loop Result_Length; loop
end loop;
\end{verbatim}
\label{ex:min_com_loop_to_3}
\end{figure}
which causes another syntax error later in the code (missing
\verb|end loop;|). Here three tokens were inserted by
\verb|Minimal_Complete|; \verb|.. loop ;|.

%% - minimal complete similar to Fischer and Mauney 1992, refs Fisher,
%% Milton, Quiring 1980 (FMQ 1980); those are for LL(1) parsers
%% S(A) = x such that A => x and Cost(x) is minimized = Terminal_Sequence (all cost 1)

\subsection{Matching\_Begin}
%% FMQ 1980) E(A,a) = x : A => xay, cost (x) minimal => superset of matching_begin?

\subsection{Language\_Fix}

\section{interaction with generalized parsing}
\section{Computing Minimal\_Complete}
\label{minimal-complete-compute}

\section{Bibliography}
\begin{thebibliography}{9}

\bibitem{Emacs Ada mode news} http://www.nongnu.org/ada-mode/NEWS-ada-mode.text

\bibitem{Grune 2008} ``Parsing Techniques; A Practical Guide, Second
  Edition''. Dick Grune, Ceriel J.H. Jacobs, 2008. Springer Science.

\bibitem{McKenzie 1995} McKenzie, Bruce J., Yeatman, Corey, and De
  Vere, Lorraine.
  \textit{Error repair in shift reduce parsers} ACM Trans. Prog.
  Lang. Syst., 17(4):672-689, July 1995.
  % Described in [Grune 2008] ref 321.
\end{thebibliography}
\end{document}
