%% compilation command: latex -file-line-error -interaction=nonstopmode <file>
\documentclass{article}
\usepackage{algorithm2e}[longend noline]
\usepackage{float}
\usepackage{listings}
\lstset{escapeinside={\%*}{*)}, language=Ada}
\title{Robust error correction in a generalized LR parser}
\author{Stephen Leake}

\newcommand{\code}[1]{`\lstinline|#1|'}

\begin{document}
\section{Abstract}

\section{Introduction}
Emacs Ada mode has used an LR parser to support indentation, syntax
highlighting, and navigation since 2013 \cite{Emacs Ada mode news}.
However, the parser did not provide error correction, so the
indentation was often confusing when the syntax was incorrect, as it
usually is in an interactive editing environment. This motivated the
search for error correction algorithms.

Grune \cite{Grune 2008} provides a thorough overview of error correction in
LR and LL parsers. Of those algorithms presented, McKenzie \cite{McKenzie 1995}
provides the foundation for the current work.

The McKenzie algorithm works by exploring the parse table (or
Deterministic Parsing Automata (DPA) as \cite{McKenzie 1995} calls it)
at the error point, finding tokens to insert. It also tries deleting
tokens following the error point. Each possible solution, together
with the parse stack at the error point, forms a
\textit{configuration}. Each configuration also has a cost, determined
by what tokens are inserted and deleted. At each step in the
algorithm, new configurations are generated from the current error
point. Then the minimum cost configuration is checked to see if it
succeeds; if not, more configurations are generated.

There are several situations where the McKenzie algorithm can take a
long time, or is inefficient.

For example, consider this Ada code:
\begin{figure}[H]
\begin{lstlisting}
procedure Example_01
is begin
   Msg : constant String;
begin
   Put_Line (Msg);
end;
\end{lstlisting}
\caption{}
\label{ex:extra_begin_1}
\end{figure}

There is an extra \code{begin} immediately after \code{is} (a common
occurance while editing code). However, the error is not detected
until \code{:}, which can only occur in declarations, not statements.

To fix this, the McKenzie algorithm must insert \code{; end; begin
  IDENTIFIER}, or delete \code{constant String; begin} and then insert
\code{;}. A much better solution would be to ``push back'' \code{Msg
  begin}, and then delete \code{begin}.

A harder problem is when there are several missing ``end''s, because
the user is typing a nested statement:
\begin{figure}[H]
\begin{lstlisting}
begin
   if A then
      B;
      if C then
         loop
           Do_Something;
end;
\end{lstlisting}
\caption{}
\label{ex:min_com_if_if_loop}
\end{figure}

Here we are missing several tokens: \code{end loop; end if; end if;}.
McKenzie will theoretically find the solution that inserts all of
these, but along the way it will try inserting every possible
statement as well, wasting a lot of time, and in practice hitting a
time-out limit. This article introduces the \code{Minimal\_Complete}
algorithm, which quickly finds the minimal number of tokens to insert
to complete the trailing statement in situations like this.

This article also introduces several other new operations for the core
McKenzie algorithm to try at the error point, and adapts the algorithm
to work with a generalized parser.

%% copy initial parts of mckenzie to define 'config' etc? Also dragon
%% to define "parse state", "kernel"

\section{The parsing context}
\subsection{Generalized parsing}
We use a generalized LR parser \cite{Tomita 1986}, to tolerate
conflicts in the parse table. This allows using the Ada grammar as
given in the ISO language standard appendix P \cite{Ada 2012}, which
is not LR(1). Using that grammar directly ensures we are implementing
the correct language, and simplifies updating the parser to a new
language version.

This means the main parser may have several parallel parsers executing
when an error is encountered. The McKenzie error correction algorithm
is enhanced to maintain state information for each parser. When more
than one solution is found with the same cost, additional parsers are
created to use them.

The parser builds a syntax tree; to handle parallel parsers, we use a
branched tree similar to Tomita's sub-tree sharing. The syntax tree
will contain ``virtual tokens'' that are inserted by error correction.

The entire input token sequence is kept in memory, to allow arbitrary
push back.

\subsection{Partial parse}
In order to handle very large files, the parser supports ``partial
parse''; parsing only part of a file.

Note that this is not the same as ``incremental parse'', where an
existing syntax tree from a previous parse is modified based on a text
edit.

In order to minimize the amount of text passed, we modify the grammar
to allow smaller chunks of code to be accepted as a complete parse. In
Ada, this means adding \code{declaration} and \code{statement} to
\code{compilation\_unit}.

When the file length is greater than a threshold, Emacs invokes a
partial parse whenever a parse is needed. To do this, it first uses a
regular expression search to find a reasonable start point, then finds
a possible matching end that includes the requested parse position, and
passes that region to the parser.

In Ada, the search for a start point finds a block begin, or the point
after a block end. If a block begin was found, the matching end is
looked for; otherwise, the requested parse point is the end point.

This imposes a greater burden on the error correction algorithm, since
the parsed text will often be incomplete.

\section{Extensions to McKenzie}
We define the following operations that are tried in each McKenzie
step:
\begin{itemize}
\item \code{push\_back}
\item \code{undo\_reduce}
\item \code{Try\_Insert\_Quote}
\item \code{Minimal\_Complete}
\item \code{Language\_Matching\_Begin\_Tokens}
\item \code{Language\_Fixes}
\end{itemize}

\subsection{push\_back}
\code{push\_back} pops the top parse stack item, and moves the input
stream pointer back to the first terminal contained by that item. We
call the point in the input stream at which insert and delete is done
the ``edit point''; it may not be an error point. \code{push\_back}
moves the edit point.

\subsection{undo\_reduce}
\code{undo\_reduce} undoes the reduce that produced the top stack item
(which must be a nonterminal), replacing the top stack item by the
sequence of stack items just before the reduction, without
moving the edit point. This requires a syntax tree that records the
shifts and reductions done during the parse. The input pointer is not
moved. This operation serves two purposes;

1) it allows a subsequenct \code{push\_back} to push back fewer tokens.

2) it allows token insertions that would otherwise be forbidden by the
grammar.

To illustrate the second point, consider:
\begin{figure}[H]
\begin{lstlisting}
procedure Example_2
is
   I : Integer;
begin
   procedure Put_Top_10
   is begin
   ...
   end Put_Top_10;
begin
end Example_2;
\end{lstlisting}
\caption{}
\label{ex:extra_begin_2}
\end{figure}
There is an extra \code{begin} after
\code{I : Integer}. The error is detected at \code{procedure}; at that point,
the parse stack looks like (top is to the left):
\begin{verbatim}
245 : BEGIN, 208 : declarative_part, 159 : IS,
   36 : subprogram_specification, 0 :
\end{verbatim}
Here the numbers label the states, terminals are in uppercase,
nonterminals in lowercase.

The grammar productions relevant to this example are:
\begin{verbatim}
declarative_part <= declarations |  ;
declarations <= declarations declaration | declaration ;
declaration <= subprogram_declaration | ... ;
\end{verbatim}

Fixing the parse error starts by \code{push\_back BEGIN, delete BEGIN},
leaving \code{declarative\_part} on top of the stack. \code{procedure}
is the next token, which is illegal in state 208; it starts a
\code{subprogram\_declaration}, but we've already ``closed'' the
declaration section by reducing to \code{declarative\_part}. We could
do \code{push\_back declarative\_part}, but that moves the edit point to
before the object declaration for \code{I}, where there is no error
and nothing helpful to insert or delete. Instead, \code{undo\_reduce}
leaves the stack as:

\begin{verbatim}
137 : declarations, 159 : IS, 36 : subprogram_specification, 0 :
\end{verbatim}
and now \code{procedure} is legal.

We do not maintain a syntax tree for the parsing done during error
correction; doing that proved to be much too slow. Therefore the
\code{undo\_reduce} operation can only be applied to configurations
where the top stack item was produced by the main parse, so it has a
valid syntax tree entry. An exception is when the nonterminal is
empty; that is easy to undo.

\subsection{Try\_Insert\_Quote}
Missing string quotes cause problems for the McKenzie algorithm.
Consider the code:
\begin{lstlisting}
A : String := Now is the time for all good men";
\end{lstlisting}
There is a missing quote before \code{Now}. In Ada, strings cannot
cross newline, and the lexer handles the error by inserting a virtual
quote just before the existing one. Then the parser sees a list of
identifiers followed by an empty string literal. The McKenzie
algorithm would have to delete all the identifiers one by one, with a
cost for each.

The \code{Try\_Insert\_Quote} operation attempts to find a better
place to insert the string quote, depending on the relative placement
of the unbalanced quote and the parse error.

\begin{itemize}
\item If the parse error is at the unbalanced quote, assume the unbalanced
quote is the intended closing quote, and insert the opening quote one
non-empty token before it. Example:
\begin{lstlisting}
   A := "for all" & good ";
\end{lstlisting}
We are in the process of splitting a string across lines; we just
added \code{" \&}, but are missing the \code{"} before \code{good}.
This solution inserts that missing quote.

\item If the parse error is after the unbalanced quote, assume the unbalanced
quote is the intended opening quote, and insert the closing quote at
the line end. Example:
\begin{lstlisting}
   A := "for all" & "good ;
\end{lstlisting}
The missing \code{"} should be after \code{good}.
This solution inserts that missing quote.

\item If the parse error is before the unbalanced quote, assume the unbalanced
quote is the intended closing quote, and insert the opening quote:

\begin{itemize}
\item before the error token. Example:
\begin{lstlisting}
   A := for all good";
\end{lstlisting}
The missing \code{"} should be before \code{for}. The parse error is at \code{all};
this solution inserts the missing quote before \code{all}, which is
almost right.

\item one non-empty token before the unbalanced quote. Same example,
  but this inserts the \code{"} before \code{all}, which is correct.

\item If there is a string literal on the parse stack,
assume the closing quote of that string literal is new (or extra),
and extend the string literal to the unbalanced quote. Example:
\begin{lstlisting}
   A := "for all" good";
\end{lstlisting}
The \code{"} after \code{all} is extra. The parse error is at \code{good};
this solution in effect deletes the extra quote.

Note that the search for a string literal on the parse stack must take
into account nonterminals that may contain a string literal. This
requires the syntax tree mentioned in connection with
\code{undo\_reduce} above. The set of nonterminals that may contain a
string literal is provided as a function call written by the grammar
author; it is not computed from the grammar because it should not
include higher level nonterminals that are not likely to be contained
in a string; for Ada, it stops at expression.
\end{itemize}
\end{itemize}

Since the lexer recognizes string literals, we cannot actually insert
an unbalanced string quote; we actually delete all tokens between the
inserted quote and the unbalanced quote, which matches what the lexer
would have returned. This is still much better than the original
McKenzie algorithm, because we do all the deletions in one step, with
one low cost.

\subsection{Minimal\_Complete}
The \code{Minimal\_Complete} strategy is to insert the minimum number
of tokens to finish the current grammar production. This is supported
by precomputing a \code{Minimal\_Complete\_Action} (or set of actions)
for each parser state.

Section \ref{minimal-complete-compute} gives the algorithm for
computing the \code{Minimal\_Complete\_Actions}; here we describe how
they are used in error correction.

Each \code{Minimal\_Complete\_Action} is either ``insert this terminal
token'' or ``reduce to this nonterminal token''.

Consider the code in figure \ref{ex:min_com_if_if_loop}. The best error
correction is to provide all of the missing ``ends''.

When parsing this code, an error is detected at the final \code{;};
the parser is expecting \code{end loop;}. The kernel of that state has
one production:
\begin{verbatim}
loop_statement <= LOOP sequence_of_statements END ^ LOOP
   identifier_opt SEMICOLON
\end{verbatim}
where the carrot (\verb|^|) shows the parse point. In this case, it is
easy to see that \code{Minimal\_Complete\_Action} must be \code{loop}.
Similarly, after parsing \code{loop}, \code{Minimal\_Complete\_Action}
is \code{identifier\_opt}, and then \code{;}. After that, we will be
completing the inner \code{if then} statement, and then the outer
\code{if then} statement. At that point, the existing \code{end ;} is
legal.

To handle cases where only the leading part of a nonterminal
production needs to be inserted, the check to see if the original
error token is now legal must be performed after each token is
inserted; this means that \code{Minimal\_Complete} inserts at most one
token for each cycle of the underlying McKenzie algorithm.

In order to prefer the \code{Minimal\_Complete} solution over others,
we give it a negative cost. In figure \ref{ex:min_com_if_if_loop}, the
grammar is a small subset of Ada, the
default insert and delete cost is 4, delete \code{begin} is cost 1,
delete \code{END}, \code{;} are cost 2. With \code{Minimal\_Complete}
cost 0, -1, or -2, no solution for figure \ref{ex:min_com_if_if_loop}
is found, with an enqueue limit of 120,000. With
\code{Minimal\_Complete} cost -3, the desired solution is found with
cost 9, after enqueueing 6804 configurations and checking 1051.

As usual, there is a trade off here; setting the magnitude high
encourages \code{Minimal\_Complete} over other solutions, but sometimes
other solutions would be better. For example, consider:
\begin{lstlisting}
for I in 1 to Result_Length loop
end loop;
\end{lstlisting}
Here \code{to} should be \code{..} (this is an actual error the author
typed late one night). The error is detected at \code{to}, so the
desired solution is \code{delete IDENTIFIER, insert ..}. With the
\code{Minimal\_Complete} cost set to 0, this solution is found, along
with 19 other solutions with the same cost; a few of these change the
code to:

\begin{lstlisting}
in to.Result_Length loop
in 1 .. to*Result_Length loop
in 1 .. to/Result_Length loop
\end{lstlisting}

Finding these takes a relatively long time; 1273 configurations
were enqueued and 218 checked.

Setting \code{Minimal\_Complete} cost to -1 finds similar solutions,
but more quickly (341 enqueued, 56 checked); \code{insert ..} is done
by \code{Minimal\_Complete}, so it is cheaper, and more expensive
solutions are not checked.

Setting \code{Minimal\_Complete} cost to -3 (as required for
figure \ref{ex:min_com_if_if_loop}) finds one cost 3 solution very
quickly (67 enqueued, 10 checked); it changes the code to:
\begin{lstlisting}
for I in 1 .. to loop Result_Length; loop
end loop;
\end{lstlisting}
which causes another syntax error later in the code (missing
\code{end loop;}). Here three tokens were inserted by
\code{Minimal\_Complete}; \code{.. loop ;}.

In the production Ada parser, -3 proves to be a good setting for
\code{Minimal\_Complete} cost.

In some cases, the action required for \code{Minimal\_Complete} is
reduce, not shift. For example:
\begin{lstlisting}
case Current_Token is
= +RIGHT_PAREN_ID then
   Matching_Begin_Token := +LEFT_PAREN_ID;
else
   Matching_Begin_Token := Invalid_Token_ID;
end if;
\end{lstlisting}
%% minimal_complete_convert_if_to_case.ada_lite
Here the user is in the middle of converting an \code{if} statement to
a \code{case} statement. The relevant grammar productions (for
\code{if\_statement} and \code{case\_statement}) are:
\begin{verbatim}
if_statement
  : IF expression_opt THEN sequence_of_statements elsif_statement_list
    ELSE sequence_of_statements END IF SEMICOLON ;
case_statement
  : CASE expression_opt IS case_statement_alternative_list
    END CASE SEMICOLON ;
\end{verbatim}
An error is detected at \code{=}; \code{Minimal\_Complete} inserts
\code{when NUMERIC\_LITERAL =>}, then the original McKenzie algorithm
inserts \code{if NUMERIC\_LITERAL}, which makes the remaining code
legal, terminating one error correction session. Then parsing proceeds
to then end of the input, where another error is enountered; missing
\code{end case;}. At that point, the parse state kernel has one
production:
%% ada_lite_lr1.parse_table, state 2891
%% 98.1:
%% reduces to
\begin{verbatim}
if_statement <= IF expression_opt THEN sequence_of_statements
   ELSE sequence_of_statements END IF SEMICOLON ^;

Minimal_Complete_Action => if_statement
\end{verbatim}
Since the \code{Minimal\_Complete\_Action} token is a nonterminal, the action
is reduce, not shift. That leads to several more states where the
\code{Minimal\_Complete\_Action} is reduce:
%% states 1711, 1708
\begin{verbatim}
compound_statement <= if_statement ^
Minimal_Complete_Action => compound_statement

statement <= compound_statement ^
Minimal_Complete_Action => statement

  ...
\end{verbatim}

and finally arrives at the
state kernel:
%% state 370
\begin{verbatim}
case_statement <= CASE expression_opt IS
   case_statement_alternative_list ^ END CASE SEMICOLON
case_statement_alternative_list <=
   case_statement_alternative_list ^ case_statement_alternative

Minimal_Complete_Action => END
\end{verbatim}
which inserts \code{end}. \code{Minimal\_Complete} does all required
reductions, and one insertion, in one McKenzie step.

If there is more than one production in the kernel for a parse state
that gives the minimum length for that state, there is more than one
\code{Minimal\_Complete\_Action} for that state. In that case, we look
at the length after the parse point for each production in the kernel
for the state that the shift or reduce goes to; if one of the actions
results in a minimum length, that action is chosen. If more than one
action gives the minimum length, all are kept. Therefore
\code{Minimal\_Complete} maintains a queue of configurations with an
action to check. Each may produce a new configuration for the next
McKenzie step.

Consider the Java code fragment:
\begin{figure}[H]
\begin{lstlisting}
{ B = UpdateText (A }
\end{lstlisting}
\caption{}
\label{ex:recursive_length_after_dot}
\end{figure}
% minimal_complete_recursive_length_after_dot.java_exp_ch19
This is missing \code{);} after \code{A}. The error is detected at
`\lstinline|}|'. At that point, the kernel is:
%% java_expressions_ch19_lr1.parse_table state 22
\begin{verbatim}
LambdaExpression <= Identifier ^ MINUS_GREATER Identifier
LeftHandSide <= Identifier ^
ClassType <= Identifier ^
MethodInvocation <= Identifier ^ LEFT_PAREN ArgumentList RIGHT_PAREN

Minimal_Complete_Action => (LeftHandSide, ClassType)
\end{verbatim}
Here both actions are reduce, so we have to look at the next state.
Reducing to \code{LeftHandSide} goes to state 27:
\begin{verbatim}
Assignment <= LeftHandSide ^ EQUAL Expression ; recursive
Minimal_Complete_Action => EQUAL
\end{verbatim}
Here the production is labeled \code{recursive}, because it is part of
a recursion cycle in the grammar. The grammar is a subset of Java; the
productions involved in this recursion cycle are:
\begin{verbatim}
Assignment           <= LeftHandSide ^ EQUAL Expression
Expression           <= LambdaExpression  | AssignmentExpression
AssignmentExpression <= AdditiveExpression | Assignment
\end{verbatim}
This says that an \code{Expression} in this grammar can be \code{A :=
  B := C := 1}. Thus it makes no sense for \code{Minimal\_Complete} to
insert \code{:=}; that will never result in a minimal length. In
general, recursive productions are never minimal length, so
\code{Minimal\_Complete} drops them, unless all the productions in a
kernel are recursive. Then the recursion is ignored, and all the
actions are queued; one of the later states will break the recursion.
This requires a \code{recursive} flag stored for each kernel item in
each parse state. Note that since we normally set the cost of a
\code{Minimal\_Complete} step negative, we cannot rely on cost to
eliminate recursive productions.

Getting back to figure \ref{ex:recursive_length_after_dot}, reducing
to \code{ClassType} goes to state 33:
\begin{verbatim}
PostfixExpression <= ClassType ^
ClassType <= ClassType ^ DOT Identifier ; recursive

Minimal_Complete_Action => PostfixExpression 31.0
\end{verbatim}
Here \code{PostfixExpression} is not recursive, so that is chosen. We
cannot compute a length from this production because there are no
tokens after the parse point; we have to follow the reduce to the next
state, and the next, until we find a shift. Several more single-token
reductions are done, ending with:
%% states 30 29 28 25 23 84
\begin{verbatim}
MethodInvocation <= Identifier LEFT_PAREN ArgumentList ^ RIGHT_PAREN
ArgumentList <= ArgumentList ^ COMMA Expression ; recursive

Minimal_Complete_Action => RIGHT_PAREN
\end{verbatim}
which shifts \code{)}. All of these reductions, and the final shift,
are done in one McKenzie step. The function that computes the length
after parse point is recursive.

Consider the following code:
\begin{figure}[H]
\begin{lstlisting}
{ UpdateText (A) }
\end{lstlisting}
\caption{}
\label{ex:minimal_complete_all_recursive}
\end{figure}
% minimal_complete_all_recursive.java_exp_ch19
In the subset of Java we are using for this examples, this is not a
complete statement. The relevant productions are:
\begin{verbatim}
StatementExpression     <= PostIncrementExpression | PostDecrementExpression ;
PostIncrementExpression <= PostfixExpression '++' ;
PostDecrementExpression <= PostfixExpression '--' ;
PostfixExpression       <= ClassType | MethodInvocation |
                           PostIncrementExpression | PostDecrementExpression ;
ClassType               <= Identifier | ClassType '.' Identifier ;
\end{verbatim}
To complete the code fragment in figure \ref{ex:cycle_check}, we have
to insert either \code{++} or \code{--}. The error is detected at the
closing brace; the parse state kernel is:
% java_expressions_ch19_lr1.parse_table state 62
\begin{verbatim}
MethodInvocation <= Identifier LEFT_PAREN ArgumentList RIGHT_PAREN ^
Minimal_Complete_Action => MethodInvocation
\end{verbatim}
Then we reduce to \code{PostfixExpression}, and arrive at this state:
% state 8
\begin{verbatim}
PostIncrementExpression <= PostfixExpression ^ PLUS_PLUS ; recursive
PostDecrementExpression <= PostfixExpression ^ MINUS_MINUS ; recursive
Minimal_Complete_Action => (PLUS_PLUS, MINUS_MINUS)
\end{verbatim}
There are two actions; because both states are labeled recursive, we
don't look at the next states - we enqueue two configs, one with each
shift. The next McKenzie step inserts \code{;} in each, completing the
error recovery session with two solutions. In the main parser, both
solutions parse to end of input; then one is chosen arbitrarily to be
the final parse. Note that in the absence of error correction multiple
parallel parsers getting to end of input is an error, but since error
correction often produces multiple solutions, we don't report an
error.

Consider the following code:
\begin{figure}[H]
\begin{lstlisting}
{ A, B,
\end{lstlisting}
\caption{}
\label{ex:minimal_complete_cycle_check}
\end{figure}
% minimal_complete_all_recursive.java_enum_ch19
Here we are using a different subset of Java; there are only three
productions in the grammar:
\begin{verbatim}
EnumConstantList <= EnumConstant | EnumConstantList COMMA EnumConstant ;
EnumConstant     <= IDENTIFIER ;
EnumBody         <= LEFT_CURLY_BRACKET EnumConstantList COMMA RIGHT_CURLY_BRACKET |
                    LEFT_CURLY_BRACKET COMMA RIGHT_CURLY_BRACKET ;
\end{verbatim}
The input is missing '\lstlisting|}|'; the error is detected at end of
input. The parse state kernel is:
\begin{verbatim}
EnumConstantList <= EnumConstantList COMMA ^ EnumConstant
EnumBody         <= LEFT_CURLY_BRACKET EnumConstantList COMMA ^ RIGHT_CURLY_BRACKET

Minimal_Complete_Action => (IDENTIFIER, RIGHT_CURLY_BRACKET)
\end{verbatim}


\subsection{Matching\_Begin}
Consider the code:
\begin{lstlisting}
procedure ... end;
end if;
end Foo;
\end{lstlisting}
This is a result of cut and paste.
\code{procedure Foo is begin if expression then} is missing before
\code{end if}.

The error is detected at the \code{end} in \code{end if}.
\code{Minimal\_Complete} is no help here; the parse stack looks like:
\begin{verbatim}
34 : subprogram_body, 0 :
\end{verbatim}
\code{Minimal\_Action} in state 34 is reduce to
\code{compilation\_unit}, which is then reduced to
\code{compilation\_unit\_list}, which is the grammar start symbol. So
\code{Minimal\_Complete} has nothing useful to insert.

To the grammar author, the solution is obvious. We capture that
knowledge by having the grammar author provide a function
\code{Language\_Matching\_Begin\_Tokens}, which takes the current parse
stack and the next three input tokens as input, and returns a list of
tokens to insert at the edit point.

The \code{Language\_Matching\_Begin\_Tokens} function is similar to the
table $E(A,a)$ given in \cite{FMQ 1980} for an LL parser:
\begin{equation}
E(A,a) \equiv x \, | \, A \Rightarrow^* xay, \, \mathtt{Cost(x)\; is\; minimized}
\end{equation}
However, we are using an LR parser, so that table is not directly
applicable. We could try to compute a table that gives the minimal
sequence of tokens to insert starting in any state $s$ , and
allowing any token $a$ as the next token:
\begin{equation}
M(s,a) \equiv y \, | \, A \Rightarrow^* xyaz, \, A \in Kernel(s), \, \mathtt{Cost(x)\; is\; minimized}
\end{equation}
where $x$ is the prefix of the production $A$ in state $s$.
That is the table that the McKenzie algorithm computes on the fly; it
is not worth precomputing. It is worth providing
\code{Language\_Matching\_Begin\_Tokens} to shortcut some common
situations.

In Ada, three tokens are required to determine the proper match for
\code{end}; consider:
\begin{lstlisting}
case is end case;
loop end loop;
block_1 : begin end Block_1;
package Parent_1.Child_1 is begin end Parent_1.Child_1;
\end{lstlisting}
In the case and loop statements, the three tokens starting with
\code{end} are \code{end loop ;} and \code{end case ;}; here we only
need two tokens to determine that the matching begin is \code|case| or
\code{loop}.
To distinguish between the named block statement and the package
declaration, we need three tokens; in a named block statement the name
must be a simple identifier, with no dots, so the third token must be
\code{;}.

In Ada, \code{Language\_Matching\_Begin\_Tokens} returns the proper
statement start token for \code{end ... }, and for
\code{then, else, elsif, exception}. For \code{when}, it returns
\code{case IDENTIFIER is}, which assumes a partial case statement is
more common than a partial exception handler. For any other error
token, it returns an empty sequence; no guess is better than a bad
guess.

\code{Language\_Matching\_Begin\_Tokens} also returns a flag
\code{Forbid\_Minimal\_Complete}, which is True when
\code{Minimal\_Complete} would be harmful. In Ada, this is set True
when the error point is after \code{end} in one of the \code{end}
sequences above; it is better to push back \code{end}.

\subsection{Language\_Fixes}
To take advantage of the redundant block name information in Ada, we
provide a general hook \code{Language\_Fixes}; it takes as input all of
the current error recovery state, and enqueues new configurations to
test.
Consider:
\begin{lstlisting}
procedure Proc_1
is begin
    Block_1:
    begin
end Proc_1;
\end{lstlisting}
Here \code{end Block\_1;} is missing. The grammar rules for Ada do not
require the start and end block names to match; that is checked later
in the compilation process. To take advantage of it for error
correction, we add that check as a parse-time action in the grammar
declaration:
\begin{verbatim}
block_statement
  : block_label_opt BEGIN handled_sequence_of_statements END
    identifier_opt SEMICOLON
    %()%
    %(return Match_Names
        (Lexer, Descriptor, Tokens, 1, 5, End_Name_Optional);)%
  ;
\end{verbatim}
Here the first `\verb|%()%|' gives the post-parse action, which is run
after the parse is complete and the syntax tree is available; Emacs
uses this action to compute indent, navigation, and highlight. The
second `\verb|%()%|' gives the in-parse action, which is run when the
production is reduced, both in the main parse and during error
correction.

Here \code{Match\_Names} will return a status of
\code{Match\_Names\_Error} if the names do not match, with the error
point after the final \code{;}, and the production not reduced (so it
is possible to edit the token sequence without an
\code{undo\_reduce}). \code{Language\_Fixes} then tries to determine
the best fix based on the name information.

In this example, the check fail is reported after \code{end Proc\_1;}.
\code{Language\_Fixes} finds the matching \code{procedure Proc\_1} on
the parse stack, and inserts \code{end Block\_1;} before
\code{end Proc\_1;}.

Consider:
\begin{lstlisting}
package Parent_1.Child_1
is begin
    begin
end Parent_1.Child_1;
\end{lstlisting}
Here we might expect \code{Match\_Names} will fail with
\code{Extra\_Name\_Error}, but instead we get a parse error on \code{.}
in \code{Parent\_1.Child\_1}; block names must be simple identifiers.
Since this is similar to \code{Match\_Names\_Error},
\code{Language\_Fixes} handles it, finding the matching name; the
fix is to insert \code{end ;} before \code{end Parent\_1.Child\_1;}.

Consider:
\begin{lstlisting}
Block_1 :
begin
    if A then
       null;
end Block_1;
\end{lstlisting}
Here we get a syntax error on the final \code{Block\_1}; \code{if} is
expected. Again, \code{Language\_Fixes} handles it, finding the
matching name.

More complex patterns can be recognized in \code{Language\_Fixes}; see
the production Ada code.

\section{Computing Minimal\_Complete}
\label{minimal-complete-compute}
To compute the \code{Minimal\_Complete\_Action} for each state, we
first compute the recursions. A `{\it recursion}' is the result of a
cycle in the grammar; for example, consider:
\begin{verbatim}
association_list
  : association_list COMMA association_opt
  | association_opt
  ;
\end{verbatim}
The first right hand side (RHS) is direct left recursive; the second
is not recursive.

Recursion can also be indirect; consider:
\begin{verbatim}
name
  : IDENTIFIER
  | selected_component
  ;
selected_component : name DOT IDENTIFIER ;
\end{verbatim}
Together, \code{name, selected\_component} are indirect single recursive.

There are four posibilities for recursion in an RHS: \code{none,
single, middle, left, right}. \code{single} means there is only one
token in the RHS, as in \code{selected\_component}. \code{left, right}
mean the recursive token is at the left or right end of the RHS;
\code{middle} means it is at neither end.

We can form a graph representing the grammar by taking the
nonterminals as the graph vertices, and if there is a production $A
\Rightarrow xBy$ then there is a directed edge from the $A$ to $B$.
Then recursion is represented by a cycle in the graph.

In a useful grammar, every recursion must have a non-recursive
RHS in one of the nonterminals, to terminate the recursion.

We use Johnson's algorithm \cite{graph-cycles} to find the cycles in
the graph. However, that algorithm does not apply to `{\it
  multigraphs}', which have more than one edge connecting any two
nodes. Real grammars can be multigraphs, so we first filter out all
such edges, and add them back after we compute the cycles.

Some languages have a lot of recursion, so it can be prohibitive to
compute the exact set of cycles in the graph. For example, Java (using
the grammar given in chapter 19 of the language reference manual
\cite{javarm}) takes too long to compute. In that case, we only
compute the strongly connected components (which is one of the steps
in \cite{graph-cycles}), and use that as the recursion. This gives
more recursion than necessary, but still gives good performance in
error correction.

Next, we compute the minimal terminal token sequence for each production.
This is the same as $S(A)$ from FMQ \cite{FMQ 1980}:
\begin{equation}
S(A) \equiv x \in V_t^* \, |\, A \Rightarrow^* x, \, \mathtt{Cost(x)\; is\; minimized}
\end{equation}
where the cost of each token is 1.

The computation is straight-forward, except that some productions are
recursive.

Next we need $MINFIRST(A)$, which is the first token in $S(A)$, or the
invalid token $\xi$ if $S(A)$ is empty.

\begin{verbatim}

(from Immediate\_recursive)
       --  Direct left recursion is never minimal; for example, consider
         --  ada_lite LALR state 149:
         --
         --  61.0:association_list <= association_list ^ COMMA association_opt
         --
         --  If we already have an association_list, adding a COMMA to it
         --  cannot be minimal.
         --
         --  Similarly, indirect left recursion is not minimal; consider
         --  ada_lite LALR states 29 and 60:
         --
         --  State 29:
         --  103.3:name <= selected_component ^,
         --
         --  State 60:
         --   94.0:function_specification <= FUNCTION name ^ parameter_and_result_profile
         --  103.0:name <= name ^ LEFT_PAREN range_list
         --  103.1:name <= name ^ actual_parameter_part
         --  123.0:selected_component <= name ^ DOT IDENTIFIER
         --
         --  If we already have a name, adding actual_parameter_part or DOT IDENTIFIER cannot be
         --  minimal.

         --  There is a trade off here between error recovery power and risk of
         --  recursive loops. Consider ada_lite state 152:
         --
         --  103.0:name <= name LEFT_PAREN range_list ^ RIGHT_PAREN
         --  117.0:range_list <= range_list ^ COMMA range_g
         --
         --  Both productions are Left_Recursive, but in the first item, dot is past
         --  the recursion, and can be usefully completed.
         --
         --  However, that might allow loops; see java_enum_ch19.wy.
         --
         --  A similar argument applies to right recursive items; from
         --  java_expressions_ch19.wy:
         --
         --  State 7:
         --  27.0:Assignment <= LeftHandSide ^ EQUAL Expression
         --
         --  State 22:
         --  28.0:LeftHandSide <= Identifier ^
         --  34.0:ClassType <= Identifier ^
         --
         --  State 25:
         --  24.1:Expression <= AssignmentExpression ^
         --
         --  State 26:
         --  26.1:AssignmentExpression <= Assignment ^
         --
         --  Choosing LeftHandSide for the minimal action in state 22 will lead
         --  to a loop thru state 7. However, Assignment can also occur in
         --  Statement, where it is not recursive:
         --
         --  State 1:
         --  23.0:Statement <= LEFT_CURLY_BRACKET ^ Assignment RIGHT_CURLY_BRACKET
         --
         --  This is not easy to check for.
         --
         --  It is not expensive to check for loops in Minimal_Complete_Action
         --  at run-time, so given all the above we allow items that are "past
         --  the recursion" here.

  (from Delete\_Non\_Minimal)
        --  The absolute minimal production for an LHS may not be in this
      --  state. For example, for an Ada aggregate, the absolute minimal
      --  terminal sequence is:
      --
      --  aggregate <= LEFT_PAREN RIGHT_PAREN
      --
      --  but one state has only:
      --
      --  aggregate <= LEFT_PAREN expression_opt WITH ^ NULL RECORD RIGHT_PAREN
      --  aggregate <= LEFT_PAREN expression_opt WITH ^ association_list RIGHT_PAREN
      --
      --  Find the minimum tokens after dot of the productions that are present

\end{verbatim}

\section{Implementation}
%% optimize data structures for speed; fixed length queue, stack;
%% fibonacci heap
%% multiple threads
%% LR1 vs LALR

\section{Code}
\label{code}
\begin{lstlisting}
  %*\lstset{numbers=left} *)
procedure Set_Minimal_Complete_Actions
  (State                      : in out Parse_State;
   Kernel                     : in     LR1_Items.Item_Set;
   Descriptor                 : in     WisiToken.Descriptor;
   Grammar                    : in     WisiToken.Productions.Prod_Arrays.Vector;
   Minimal_Terminal_Sequences : in     Minimal_Sequence_Array;
   Minimal_Terminal_First     : in     Token_Array_Token_ID)
is
   use all type Ada.Containers.Count_Type;
   use LR1_Items.Item_Lists;
   use Token_ID_Arrays;

   subtype Terminals is Token_ID range
      Descriptor.First_Terminal .. Descriptor.Last_Terminal;

   Working_Set : LR1_Items.Item_Lists.List := Kernel.Set;
   Recursive   : Boolean := False;

   function Find_Action (List : in Action_Arrays.Vector; ID : in Token_ID)
      return Minimal_Action
   is begin
      --  ID is a terminal after Dot in an item in a kernel that has List as
      --  the actions; return the appropriate action.
      for Node of List loop
         if Node.Symbol = ID then
            case Node.Actions.Item.Verb is
            when Shift =>
               return (Shift, ID, Node.Actions.Item.State);
            when Reduce =>
               --  Item.Dot is a nonterm that starts with a nullable nonterm; reduce
               --  to that first. After any more such reductions, the action will be
               --  Shift ID.
               return (Reduce, Node.Actions.Item.Production.LHS, 0);
            when Accept_It | WisiToken.Parse.LR.Error =>
               raise SAL.Programmer_Error;
            end case;
         end if;
      end loop;
      raise SAL.Programmer_Error;
   end Find_Action;

   procedure Delete_Non_Minimal
   is
      use Ada.Containers;

      Min_Length       : Count_Type := Count_Type'Last;
      I                : LR1_Items.Item_Lists.Cursor;
      Recursive_Count  : Count_Type := 0;
      Delete_Recursive : Boolean;

      function Immediate_Recursive return Boolean
      is
         Item : LR1_Items.Item renames Constant_Ref (I).Element.all;
         Prod : constant WisiToken.Production_ID := Item.Prod;
         Min_Seq : RHS_Sequence renames Minimal_Terminal_Sequences (Prod.LHS)(Prod.RHS);
      begin
         return Min_Seq.Worst_Recursion in Right | Left and then
           (Has_Element (Item.Dot) and then
              Item.Dot = To_Cursor (Grammar (Prod.LHS).RHSs (Prod.RHS).Tokens, 2));
      end Immediate_Recursive;

   begin
      I := Working_Set.First;
      loop
         exit when not Has_Element (I);

         if Immediate_Recursive then
            Recursive_Count := Recursive_Count + 1;
         end if;

         Next (I);
      end loop;

      Delete_Recursive := Recursive_Count < Working_Set.Length;

      I := Working_Set.First;
      loop
         exit when not Has_Element (I);

         if Delete_Recursive and Immediate_Recursive then
            declare
               Del : LR1_Items.Item_Lists.Cursor := I;
            begin
               Next (I);
               Working_Set.Delete (Del);
            end;

         else
            Recursive := Recursive or Minimal_Terminal_Sequences
              (Constant_Ref (I).Prod.LHS)(Constant_Ref (I).Prod.RHS).Worst_Recursion in
              Left | Right;

            declare
               Prod_Length : constant Count_Type := After_Dot_Length (Constant_Ref (I));
            begin
               if Min_Length > Prod_Length then
                  Min_Length := Prod_Length;
               end if;
            end;

            Next (I);
         end if;
      end loop;

      --  Now we have the minimum length; check remaining items against that
      I := Working_Set.First;
      loop
         exit when not Has_Element (I);
         if Min_Length < After_Dot_Length (Constant_Ref (I)) then
            declare
               Del : LR1_Items.Item_Lists.Cursor := I;
            begin
               Next (I);
               Working_Set.Delete (Del);
            end;
         else
            Next (I);
         end if;
      end loop;
   end Delete_Non_Minimal;

begin
   if Kernel.State > 0 then
      --  State 0 has dot before all tokens, which is never needed in the
      --  Minimal_Action algorithm.
      declare
         use Ada.Containers;
         I : Count_Type := 1;

         function Before_Dot (Item : in LR1_Items.Item) return Token_ID
         is
            Tokens : Token_ID_Arrays.Vector renames Grammar
               (Item.Prod.LHS).RHSs (Item.Prod.RHS).Tokens;
         begin
            if Item.Dot = Token_ID_Arrays.No_Element then
               return Tokens (Tokens.Last_Index);
            else
               return Tokens (Prev (Item.Dot));
            end if;
         end Before_Dot;
      begin
         State.Kernel.Set_First_Last (1, Kernel.Set.Length);
         for Item of Kernel.Set loop
            State.Kernel (I) :=
              (LHS              => Item.Prod.LHS,
               Before_Dot       => Before_Dot (Item),
               Length_After_Dot => After_Dot_Length (Item),
               Recursive        => Minimal_Terminal_Sequences
                 (Item.Prod.LHS)(Item.Prod.RHS).Worst_Recursion in Right | Left);

            I := I + 1;
         end loop;
      end;
   end if;

   if (for some Item of Working_Set =>
         Item.Prod.LHS = Descriptor.Accept_ID and
         (Has_Element (Item.Dot) and then Element (Item.Dot) = Descriptor.EOI_ID))
   then
      --  No actions
      return;
   end if;

   Delete_Non_Minimal;

   State.Minimal_Complete_Actions_Recursive := Recursive;

   if Working_Set.Length > 0 then
      --  There are one or more productions with equal after-dot length in
      --  this state, all equally valid; the choice is determined by what
      --  input error recovery inserts.
      --
      --  We could simply choose one arbitrarily, but that can lead to loops
      --  (see discussion above in Immediate_Recursive). So we consider the
      --  higher level production. However, in general we cannot precompute
      --  what higher-level productions might be completed from each state;
      --  we must use the parse stack during error recovery. In that case,
      --  we store multiple minimal actions in the state (see
      --  Insert_Minimal_Complete_Actions in
      --  wisitoken-parse-lr-mckenzie_recover-explore.adb).

      declare
         Actions : Minimal_Action_Array (1 .. Working_Set.Length) := (others => (others => <>));

         I    : Ada.Containers.Count_Type := Actions'First;
         Skip : Boolean;
      begin
         for Item of Working_Set loop

            if not Has_Element (Item.Dot) then
               --  Item has no next terminal. Include a reduce action; the
               --  Minimal_Terminal_First for the resulting state will be used.
               Actions (I) :=
                 (Reduce, Item.Prod.LHS,
                  Token_Count => Grammar (Item.Prod.LHS).RHSs (Item.Prod.RHS).Tokens.Length);
            else
               declare
                  ID : constant Token_ID := Element (Item.Dot);
               begin
                  if ID in Terminals then
                     Actions (I) := Find_Action (State.Action_List, ID);

                  else
                     if Minimal_Terminal_First (ID) = Invalid_Token_ID then
                        --  Item.Dot is a nullable nonterm; include a reduce to the null
                        --  nonterm, rather than a shift of the following terminal; recover
                        --  must do the reduce first.
                        Actions (I) := (Reduce, ID, Token_Count => 0);

                     else
                        Actions (I) := Find_Action (State.Action_List, Minimal_Terminal_First (ID));
                     end if;
                  end if;
               end;
            end if;
            I := I + 1;
         end loop;

         if Actions'Length = 1 then
            State.Minimal_Complete_Actions := Minimal_Action_Arrays.To_Vector (Actions (Actions'First));
         else
            --  Check for duplicates; see three_action_conflict_lalr.parse_table
            --  state 3 or lalr_generator_bug_01_lalr.parse_table state 28
            for I in Actions'Range loop
               Skip := False;
               for J in Actions'First .. I - 1 loop
                  if Actions (I) = Actions (J) then
                     Skip := True;
                     exit;
                  end if;
               end loop;
               if not Skip then
                  State.Minimal_Complete_Actions.Append (Actions (I));
               end if;
            end loop;
         end if;

         if Trace_Generate > Extra then
            Ada.Text_IO.Put_Line
              (Image (State.Minimal_Complete_Actions, Descriptor) & (if Recursive then " recursive" else ""));
         end if;
      end;
   end if;
end Set_Minimal_Complete_Actions;

\end{lstlisting}
\section{Bibliography}
\begin{thebibliography}{9}

\bibitem{Ada 2012} \verb|http://ada-auth.org/standards/ada12.html|

\bibitem{Emacs Ada mode news} http://www.nongnu.org/ada-mode/NEWS-ada-mode.text

\bibitem{FMQ 1980}  Fischer, C.N., Milton, D.R., Quiring, S.B.:
  Efficient LL(1) error correction and recovery using only insertions.
  Acta Inf. 13(2), 141-154 (1980)

\bibitem{graph-cycles} Donald B. Johnson, Finding all the Elementary Circuits of a Directed Graph.
SIAM J. Comput. Vol 4, No. 1, March 1975. \url{https://epubs.siam.org/doi/abs/10.1137/0204007}

\bibitem{Grune 2008} Dick Grune, Ceriel J.H. Jacobs: ``Parsing Techniques; A Practical Guide, Second
  Edition''. Springer Science  2008.

\bibitem{javarm}
  \url{https://docs.oracle.com/javase/specs/jls/se12/html/index.html}

\bibitem{McKenzie 1995} McKenzie, Bruce J., Yeatman, Corey, and De
  Vere, Lorraine. Error repair in shift reduce parsers. ACM Trans.
  Prog. Lang. Syst., 17(4):672-689, July 1995.
  % Described in [Grune 2008] ref 321.

\bibitem{Tomita 1986} Masaru Tomita. Efficient parsing for natural language. Kluwer Academic Publishers, Boston, 1986.
\end{thebibliography}
\end{document}
