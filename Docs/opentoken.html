<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="Author" content="Ted Dennison">
   <meta name="Author" content="Stephen Leake">
   <title>OpenToken</title>
</head>
<body>

<h1> OpenToken</h1>
<p><a href="#History">History</a></p>

<h1> current version: 6.0b</h1>

<p>OpenToken may be obtained in several ways:
<ul>
  <li><a href="opentoken-6.0b.tar.bz2">source Gnu tar bzip2 opentoken-6.0b.tar.bz2</a>
  <li><a href="opentoken-6.0b.zip">source zip opentoken-6.0b.zip</a>
  <li>Debian binary package "libopentoken", source package "opentoken"
  <li><a href="http://www.stephe-leake.org/ada-france-access.html">monotone server www.ada-france.org</a>, branch org.opentoken. Maintained by <a href="mailto:ludovic@ludovic-brenta.org">Ludovic Brenta</a>
</ul>

<p>OpenToken uses Ada 2012 containers, so it requires a current Ada
2012 compiler. In particular, the current Debian stable
(Debian 7.0 "Wheezy") GNAT compiler does not support OpenToken; the next Debian release
(Debian 8.0 "Jessie") will. (see
 <a href="https://people.debian.org/~lbrenta/debian-ada-policy.html#Timeline-of-GNAT-releases">Debian
policy release timeline</a>).</p>

<p>OpenToken is a facility for performing token analysis and parsing
  within the Ada language. It supports two modes of parser
  programming; code generation similar to yacc, and Ada packages to
  construct the grammar and parse tables directly at run-time.

  For small languages, the Ada package approach is easy to use and
  maintain. For larger languages, the code generation approach is
  better; the grammar description is more compact and easier to relate
  to other language tools.

<p>For an Ada package example, here is an OpenToken LR specification
of a typical arithmetic grammar, taken from Example 5.10, section 5.3,
page 295 of
<a href="http://en.wikipedia.org/wiki/Dragon_Book_%28computer_science%29">
the red dragon book</a> (note that we have added an explicit EOF (end
of file) symbol):

<pre>
Grammar specification:

L -> E EOF
E -> E + T
E -> T
T -> T * F
T -> F
F -> ( E )
F -> integer

Ada code:

Grammar : constant Production_List.Instance :=
 L <= E & EOF                      + Print_Value'Access and
 E <= E & Plus & T                 + Add_Integers       and
 E <= T                                                 and
 T <= T & Times & F                + Multiply_Integers  and
 T <= F                                                 and
 F <= Left_Paren & E & Right_Paren + Synthesize_Second  and
 F <= Int_Literal;
</pre>

<p>This grammar is processed at runtime into a state machine data
structure, then used to parse input text. It uses dynamic memory
allocation at runtime to hold a stack of the tokens and productions.

<p>Here is a specification of an equivalent grammar, rewritten to
allow a recursive-descent implementation:

<pre>
Grammar specification:

L -> E  EOF
E -> T {+ T}
T -> F {* F}
F -> ( E )
F -> integer

Ada code:

E : Operation_List.Handle    := new Operation_List.Instance;
F : Integer_Selection.Handle :=
 (Left_Paren & E & Right_Paren + Build_Parens'Access or Int) + Build_Selection'Access;
T : Operation_List.Handle    := F ** Times * Times_Element'Access + Init_Times'Access;
L : Integer_Sequence.Handle  := E & EOF + Build_Print'Access;

E.all := Operation_List.Get
 (Element     => T,
  Separator   => Plus,
  Initialize  => Init_Plus'Access,
  Add_Element => Plus_Element'Access);
</pre>

<p>This grammar is used directly at runtime to parse input text. It
does not use dynamic memory allocation during parsing (dynamic memory
allocation is used while building the grammar in the statements
above), but it does use more stack space than the LR version. Both
parsers are reasonably efficient.

<p>OpenToken also allows implementing horribly inefficient recursive
descent grammars that still work; it supports infinite lookahead with
backtracking. This can be useful when just getting started with
parsers; first get it working, then optimize it.

<p>The lexer phase of OpenToken parsers is implemented by classes of
recognizers. Each recognizer runs in parallel, and the one matching
the longest input lexeme wins. This is not as efficient as traditional
lexers, for example those generated by <a
href="http://dinosaur.compilertools.net/lex/index.html">lex</a>, since
those use a finite state machine. But it is easier to use, because the
recognizers are already written, well documented, and can be
independently tested.

<p>Some reusable parse tokens are also included in OpenToken, but they
tend to be domain-specific.

<p>Ada's type safety features make misbehaving lexers and parsers
easier to debug. In addition, OpenToken includes a trace feature, that
outputs useful information during grammar compile and user input
parsing, also aiding debugging.

<p>OpenToken is distributed under <a
href="http://www.gnu.org/licenses/licenses.html#GPL">GPL version
3</a>, with the GNAT modification that allows use in non-GPL
projects.

<p>OpenToken was originally written by Ted Dennison. Contributions were
made by Christoph Grein and Stephen Leake.

<p>OpenToken is currently maintained by <a
href="mailto:stephen_leake@stephe-leake.org">Stephen Leake</a>. Submit
bugs directly to Stephen. Discussion about OpenToken is on the
newsgroup comp.lang.ada.

<p>OpenToken has been tested on the following operating systems/compilers:
<ul>
  <li>Debian 7.0 (wheezy) GNAT GPL 2014
  <li>Debian 8.0 (jessi) gcc 4.9.2
  <li>Windows 7 64 bit GNAT GPL 2014 32 bit
</ul>

<p>The simplest way to use the source distribution is to install it in
the standard GNAT directories, where the compiler will find it by
default. This assumes you have write permission in the GNAT directory
tree. Then just put 'with "OpenToken";' in your project file. To
install it using a bash shell (Cygwin on Windows, or Linux), and
assuming GNAT and 'make' are in your PATH:

<pre>
cd opentoken/build/release
make install
</pre>

<p>See <a href="opentoken_developer_tools.html">developer
instructions</a> if you want to run the tests or work on OpenToken,
and for hints in case the above does not work.

<p>Ted's <a
href="http://www.telepath.com/~dennison/Ted/OpenToken/OpenToken.html">original
OpenToken web page</a> is no longer being maintained. The AdaPower
mailing list and discussion board are no longer used.

<p>There is a <a href="UsersGuide.html">User's Guide</a> that
describes how to create a simple application using OpenToken. There
are also several examples in the source; see the <tt>Examples</tt>
directory. The Test directory also has useful examples, although
oriented towards testing OpenToken itself.

<h2><a name="History"></a> History</h2>

<h3>Version 6.0b 10 May 2015</h3>
<ul>
  <li>Fix minor bugs reported in 6.0a

</ul>

<h3>Version 6.0a 5 Apr 2015</h3>
<ul>
  <li>Extend parser to generalized LALR (spawn parallel parsers) to handle conflicts
  <li>Extensive API changes to support the restructured parser.
  <li>New text feeder opentoken-text_feeder-counted_gnat_os_lib
  <li>New recognizer OpenToken.Recognizers.based_integer_real_ada for Ada numeric literals
  <li>Enforce canonical order for shift/reduce conflicts; don't use
  reduce/shift conflicts.

  <li>wisi-generate
    <ul>
      <li>improve .wy comment handling
      <li>Ada_Emacs outputs full Ada code for generalized LALR parser,
      with pre-computed parser tables, for use with Emacs ada-mode
    </ul>
  <li>fix bugs
</ul>

<h3>Version 5.0b 18 Nov 2014</h3>
<ul>
  <li>Language_Lexers/ada_lexer.ads: add 'some' keyword for Ada 2012
  <li>wisi-generate
    <ul>
      <li>report unbalanced parens, brackets in actions
      <li>support wisi numeric literals
    </ul>
  <li>fix bugs
</ul>

<h3>Version 5.0a 9 Feb 2014</h3>
<ul>
    <li>Fix Debian bug 703361; OpenToken.Token.Enumerated.Analyzer.Column function is off by 1 for all lines other than the first.
    <li>Improve library installation on Windows, Linux, Mac
    <li>API changes
        <ul>
            <li>OpenToken.Production.Parser.LALR now takes a generic parameter First_State_Index
            <li>OpenToken.Production.Parser.LALR.Generate now takes additional output control parameters
            <li>OpenToken.Production.Parser.LALR: numerous bugs fixed, mostly around handling empty productions. Support generating parser tables for a generalized LALR parser.
            <li>OpenToken.Recognizer.Bracketed_Comment now has a Value function that returns the comment text.
            <li>OpenToken.Recognizer.Identifier.Get no longer has defaults for Start_Chars, Body_Chars
            <li>OpenToken.Text_Feeder.Text_IO.Create now takes an argument
            <li>OpenToken.Token.Analyzer takes more generic parameters, and imposes an order on Token_ID.
            <li>OpenToken.Token.Enumerated takes more generic parameters
            <li>OpenToken.Token.Enumerated.Input_Feeder deleted; use Set_Text_Feeder
            <li>OpenToken.Token.Enumerated.Token_ID type: Non-reporting tokens must appear first
        </ul>
</ul>

<h3>Version 4.0b 29 Jun 2010</h3>

<ul>
  <li>Packaging change to work around Debian packaging mixup; also
  changed from gzip to bzip2.
  <li>Improved this web page.
</ul>

<h3>Version 4.0a 7 Feb 2010</h3>
<ul>

  <li>Lookahead and backtracking is actually supported in recursive
      descent parsers. This required several changes:

      <ul>

        <li>Could_Parse_To is gone; the same purpose is served by
            Parse (Actively => False).

        <li>Raise_Parse_Error is gone; the message composed by the
            provided packages is already excellent.

        <li>Token types derived from Enumerated.Instance that need to
            store the Lexeme and/or Recognizer passed in Create need
            to override the new procedure Copy. This is because Create
            is called only by Analyzer.Find_Next, not by
            Enumerated.Parse; it used to be called by both.

        <li>Enumerated.Create profile is changed; ID is not needed,
            since New_Token is in out. When you fix Create, remember
            to consider adding Copy.

        <li>Token.Sequence tokens each store a lookahead count, with a
            global default.

        <li>User defined token types that do backtracking must call
            Analyzer.Mark_Push_Back and Analyzer.Push_Back to manage
            the lookahead queue; see Token.Selection for an example.

      </ul>

  <li>Fixed major bug in LALR parser generator related to which
      production gets the accept action. This bug made many small grammars
      unworkable; now they all work.

  <li>Other enhancements
      <ul>

        <li>Syntax errors reported by LR and recursive descent parsers
            include the list of expected tokens. This requires the
            Match argument to recursive descent Parse procedures to be
            of mode 'access' instead of 'in out'.

        <li>There is a dispatching Name function to allow tokens to
            identify themselves in the list of expected tokens.

        <li>The examples have been improved to more clearly
            demonstrate the differences and similarities between LR
            parsing and recursive descent parsing with OpenToken.

        <li>The OpenToken.Token.List_Mixin, .Sequence_Mixin,
            .Selection_Mixin packages have been enhanced to support
            backtracking; the non-mixin versions are instantiations of
            them.

        <li>The OpenToken.Token.List_Mixin, .Sequence_Mixin,
            .Selection_Mixin now specify actions via procedure
            pointers at run-time, rather than via overloaded
            procedures. This significantly simplifies specifying
            recursive descent grammars.

        <li>There are new examples of recursive descent parsing,
            showing that naive grammars can work, if inefficiently.

        <li>OpenToken.Token.Enumerated.Integer_Literal, .Real_Literal,
            and .String_Literal are renamed to .Integer, .Real, and
            .String, and the Value component made publicly visible.
            This allows them to be used as valued tokens in recursive
            descent parsers.

        <li>OpenToken.Production.Parser.LALR.Set_Trace is gone; use
            OpenToken.Trace_Parse instead.

        <li>Language_Lexers.HTML_Lexer supports the <pre>&lt;pre&gt;</pre>
            tag; the contents are treated as a comment.

      </ul>

</ul>


<h3>Version 3.1 August 4, 2009</h3>
<ul>
  <li> maintainer transitioned to Stephen Leake

  <li>bugs fixed
      <ul>
        <li>opentoken-production-parser-lalr.adb Add_Action<br>
            Don't put duplicate action in twice. Tested in association_token_test.

        <li>opentoken-production-parser-lrk_item.adb Closure<br>
            Delete premature loop exit. Tested in name_token_test.

        <li>opentoken-production-parser-lrk_item.adb Goto_Transitions<br>
            Handle duplicate goto set. Tested in test_lr0_kernels.

        <li>opentoken-recognizer-integer.adb Analyze<br>
            Set verdict when Allow_Signs. Tested in recognizer_integer_test. Debian bug 536359.

        <li>opentoken-recognizer-string.adb<br>
            Set C_Style_Escape_Code_Map properly. Test in string_test-run.adb.

        <li>Language_Lexers/ada_lexer.ads, .adb<br>
            Handle Character'('x'). Debian bug 498945.

      </ul>

  <li>significant changes
      <ul>

        <li>Add trace feature; shows sequence of states followed by
            the parser. Very useful for debugging a grammar.

        <li>Generate reports shift/reduce conflicts.

        <li>Parse uses Gnu syntax to report syntax errors.

        <li>Support line, column for error messages

        <li>Allow setting the parser's text feeder.

        <li>Add a new version of HTML_Lexer that is task safe.

        <li>HTML_Lexer allows '"' and '>' in paragraphs; not clear why
            they were disallowed. It also allows more characters in
            tags.

        <li>New procedure opentoken-token-enumerated-analyzer.ads Discard_Buffered_Text<br>
            For calling parser in a loop while handling exceptions.

        <li>New recognizer opentoken-recognizer-based_integer.adb.
            Recognizes Ada integer literal with optional base. See
            recognizer_based_integer_test.adb for examples.

        <li>New token opentoken-token-enumerated-identifier.adb.
            Tested in test_token_identifier_real_string. Useful for
            user symbol names.

        <li>New tokens
            opentoken-token-enumerated-real_literal.adb,
            opentoken-token-enumerated-string_literal.adb. Tested in
            test_token_identifier_real_string

        <li>Makefiles build GNAT libraries, and install in GNAT tree.

      </ul>
  <li>New tests
      <ul>
        <li>association_token_test
        <li>name_token_test
        <li>based_integer_test
        <li>recognizer_integer_test
        <li>string_token_test
        <li>test_html_lexer (there is now a known good result for one input file)
        <li>test_lr0_kernels
        <li>test_token_identifier_real_string
      </ul>
  <li>Other changes
      <ul>
        <li>change to unix line ending
        <li>update to GPL 3
        <li>delete all CVS logs
        <li>Enforce style via -gnaty3abcefhiklM120nprtx, and
            -gnatyO ('overriding') in gnat gpl-2009, 6.2.1. This
            enforces capitalization of OpenToken, ID, HTML, etc.
        <li>Ada 2005 syntax for some 'raise exception', 'is null'
        <li>Add GNAT pragma Unreferenced where needed
        <li>Merge all Makefiles into one, in a separate Build directory
        <li>In opentoken-production-parser-lrk_item.adb Generate
            and opentoken-production-parser-lalr.adb
            LR0_Kernels; optimize computation of
            First_Derivations (was done twice).
        <li>print Ada.Tags.Expanded name in productions
        <li>generally improve readability of dump
        <li>only one Parse_Error exception declared
        <li>In Opentoken.Recognizer.Graphic_Character; add Redefine
        <li>delete gnat 3.13 workarounds
        <li>delete commented out code
      </ul>
</ul>

<h3> Version 3.0b 13 August 2000</h3>
<p> by Ted Dennison

<p>This version introduces recursive decent parsing. This
has the following advantages over table-driven parsers:
<ul>
  <li>It's simpler to implement.
  <li>It provides many more opportunities for reuse.
  <li>Its parsers are debuggable.
  <li>There's no expensive parser-generation phase.
</ul>

<p>The disadvantages are:
<ul>
<li>Its parsers are most likely a bit slower.
</ul>

<p>A general list of the changes is below:
<ul>
  <li>Renamed <i>OpenToken.Token</i> tree to <i>OpenToken.Token.Enumerated</i>.
  <li>Created a new (non-enumerated) base token type and base analyzer type in <i>OpenToken.Token.</i>
  <li>Made a Parse routine and a Could_Parse_To routine primitives of the base token type.
  <li>Created the following predefined nonterminal tokens (both as straight types, and as mixins).
      <ul>
        <li> List
        <li> Selection
        <li> Sequence
      </ul>
  <li> Fixed a bug in the bracketed comment recognizer.
  <li> Implemented a (hopefully temporary) work-around for a bug in Gnat version 3.13p.
  <li> Fixed a bug in the string recognizer where it was mishandling octal and hex escape sequences.
  <li> Changed the analyzer and the text feeders to support analyzing binary files.
  <li> The HTML lexer has been improved to be a bit faster and more flexible.
</ul>

<h3> Version 2.0 27 January 2000</h3>

<p>This is the first version to include parsing capability. The
existing packages underwent a major reorganization to accommodate the
new functionality. As some of the restructuring that was done is
incompatible with old code, the major revision has been bumped up to
2. A partial list of changes is below:

<ul>
  <li> Renamed the top level of the hierarchy from Token to <i>OpenToken.</i>
  <li> Moved the analyzer underneath the new <i>OpenToken.Token </i>hierarchy.

  <li> Renamed the Token recognizers from <i>Token.*</i> to <i>OpenToken.Recognizer.*</i>

  <li> Changed the text feeder procedure pointer into a text feeder
      object. This will allow full re-entrancy in analyzers that was
      thwarted by those global text feeders previously.

  <li> Updated the SLOC counter to read a list of files to process from
      a file. It also handles files with errors in them a bit better.

  <li> Added lalr(1) parsing capability and numerous packages to support
      it. A structure is in place to build other parsers as well.

  <li> Created a package hierarchy to support parse tokens. The word
      "Token" in OpenToken now refers to objects of this type, rather than
      to token recognizers.

  <li> An HTML lexer has been added to the language lexers.

  <li> <i>.Recognizer.Bracketed_Comment</i> now works properly with single-character terminators.
</ul>

<h3> Version 1.3.6</h3>

<p>This version fixes a rare bug in the Ada style based numeric
recognizers. The SLOC counter can now successfully count all the
source files in Gnat's adainclude directory.

<h3> Version 1.3.5</h3>

<p>This version adds a simple Ada SLOC counting program into the
examples. A bug with the Real token recognizer that caused
constraint_errors has been fixed. Also bugs causing constraint errors
in the ada-style based integer and real recognizers on long non-based
numbers have been fixed.

<h3> Version 1.3</h3>

<p>This version adds the <i>default token</i> capability to the
Analyzer package. This allows a more flexible (if somewhat
inefficient) means of error handling to the analyzer. The default
token can be used as an error token, or it can be made into a
non-reportable token to ignore unknown elements entirely.

<p>Identifier tokens were generalized a bit to allow user-defined
character sets for the first and subsequent characters. This not only
gives it the ability to handle syntaxes that don't exacly match Ada's,
but it allows one to define identifiers for languages that aren't
latin-1 based. Also, the ability to turn off non-repeatable
underscores was added.

<p>Integer and Real tokens had an option added to support signed
literals. This option is set <b>on</b> by default (which causes a
minor backward incompatibility). Syntaxes that have addition or
subtraction operators will need to turn this option off.

<p>A test to verify proper handling of default parameters was added to
the Test directory. A makefile was also added to the same directory to
facilitate automatic compiling and running of the tests. This makefile
will not work in a non-Gnat/NT environment without some
modification.

<p>New recognizers were added for enclosed comments (eg: C's /* */
comments) and single character escape sequences. Also a "null"
recognizer was added for use as a default token.

<h3> Version 1.2.1</h3>

<p>This version adds the CSV field token recognizer that was
inadvertently left out of 1.2. This recognizer was designed to match
fields in comma-separated value (CSV) files, which is a somewhat
standard file format for databases and spreadsheets. Also, the
extraneous CVS directories in the zip version of the distribution were
removed.

<h3> Version 1.2</h3>

<p>The long-awaited string recognizer has been added. It is capable of recognizing
both C and Ada-style strings. In addition, there are a great many submissions
by Christoph Grein in this release. He contributed mostly complete lexical
analyzers for both Java and Ada, along with all the extra token recognizers
he needed to accomplish this feat. He didn't need as many extra recognizers
as I would have thought he'd need. But even so, slightly less than 1/2
of the recognizers in this release were contributed by Chris (with a broken
arm, no less!)

<h3> Version 1.1</h3>

<p>The main code change to this version is a default text feeder
function that has been added to the analyzer. It reads its input from
Ada.Text_IO.Current_Input, so you can change the file to whatever you
want fairly easily. The capability to create and use your own feeder
function still exists, but it should not be necessary in most cases.
If you already have code that does this, it should still compile and
work properly.

<p>The other addition is the first version of the OpenToken user's
guide. All it contains right now is a user manual walking through the
steps needed to make a simple token analyzer. Feedback and/or ideas on
this are welcome.

<h3> Version 1.0</h3>

<p>This is the very first publicly released version. This package is
based on work I (Ted Dennison) did while working on the JPATS trainer
for FlightSafety International. The germ of this idea came while I was
trying to port a fairly ambitious, but fatally buggy Ada 83 token
recognition package written for a previous simulator. But once I was
done, I was rather suprised at the flexibility of the final product.
Seeing the possible benefit to the community, and to the company
through user-submitted enhancement and debugging, I suggested that
this code be released as Open Source. They were open-minded enough to
agree. Bravo!

<HR>
<p><a href="../index.html">my home page</a>
<a href="mailto:stephen_leake@stephe-leake.org">Author : Stephen Leake</a>
<a href="http://validator.w3.org/check?uri=referer">
<img src="../images/valid-html401.png" alt="Valid HTML 4.01!" height=31 width=88></a>
<a href="http://www.gnu.org/software/emacs/windows/ntemacs.html">
<img src="../images/emacs.png" alt="Created with Emacs" width="100" height="30"></a>
<a href="http://www.adaic.org/">
<img src="../images/adapowered2.png" alt="powered by Ada" width="200" height="50"></a>
<!-- hhmts start --> Last modified: Tue Jan 01 23:39:35 EST 2013 <!-- hhmts end -->
</body>
</html>
