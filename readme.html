<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="Author" content="Ted Dennison">
   <meta name="GENERATOR" content="Mozilla/4.5 [en] (WinNT; I) [Netscape]">
   <title>Readme</title>
</head>
<body>

<center>
<h1>
OpenToken Package Readme</h1></center>

<center>
<h1>
Version 2.0</h1></center>

<p><br>The OpenToken package is a facility for performing token analysis
and parsing within the Ada language. It is designed to provide all the
functionality of a traditional lexical analyzer/parser generator, such
as lex/yacc. But due to the magic of inheritance and runtime polymorphism
it is implemented entirely in Ada as withed-in code. No precompilation
step is required, and no messy tool-generated source code is created.
<p>Additionally, the technique of using classes of recognizers promises
to make most token specifications as simple as making an easy to read procedure
call. The most error prone part of generating analyzers, the token pattern
matching, has been taken from the typical user's hands and placed into
reusable classes. Over time I hope to see the addition of enough reusable
recognizer classes that very few users will ever need to write a custom
one. Parse tokens themselves also use this technique, so they ought to
be just as reusable in principle, athough there currently aren't a lot
of predefined parse tokens included in OpenToken.
<p>Ada's type safety features should also make misbehaving analyzers and
parsers easier to debug. All this will hopefully add up to token analyzers
and parsers that are much simpler and faster to create, easier to get working
properly, and easier to understand.
<h2>
History</h2>

<h3>
Version 2.0</h3>
This is the first version to include parsing capablity. The existing packages
underwent a major reorganization to accomodate the new functionality. As
some of the restructuring that was done is incompatable with old code,
the major revision has been bumped up to 2. A partial list of changes is
below:
<ul>
<li>
Renamed the top level of the hierarchy from Token to <i>OpenToken.</i></li>

<li>
Moved the analyzer underneath the new <i>OpenToken.Token </i>hierarchy.</li>

<li>
Renamed the Token recognizers from <i>Token.*</i> to <i>OpenToken.Recognizer.*</i></li>

<li>
Changed the text feeder procedure pointer into a text feeder object. This
will allow full re-entrancy in analyzers that was thwarted by those global
text feeders previously.</li>

<li>
Updated the SLOC counter to read a list of files to process from a file.
It also handles files with errors in them a bit better.</li>

<li>
Added lalr(1) parsing capability and numerous packages to support it. A
structure is in place to build other parsers as well.</li>

<li>
Created a package hierarchy to support parse tokens. The word "Token" in
OpenToken now refers to objects of this type, rather than to token recognizers.</li>

<li>
An HTML lexer has been added to the language lexers</li>

<li>
<i>.Recognizer.Bracketed_Comment</i> now works properly with single-character
terminators.</li>
</ul>

<h3>
Version 1.3.6</h3>
This version fixes a rare bug in the Ada style based numeric recognizers.
The SLOC counter can now successfully count all the source files in Gnat's
adainclude directory.
<h3>
Version 1.3.5</h3>
This version adds a simple Ada SLOC counting program into the examples.
A bug with the Real token recognizer that caused constraint_errors has
been fixed. Also bugs causing constraint errors in the ada-style based
integer and real recognizers on long non-based numbers have been fixed.
<h3>
Version 1.3</h3>
This version adds the <i>default token</i> capability to the Analyzer package.
This allows a more flexible (if somewhat inefficient) means of error handling
to the analyzer. The default token can be used as an error token, or it
can be made into a non-reportable token to ignore unknown elements entirely.
<p>Identifier tokens were generalized a bit to allow user-defined character
sets for the first and subsequent characters. This not only gives it the
ability to handle syntaxes that don't exacly match Ada's, but it allows
one to define identifiers for languages that aren't latin-1 based. Also,
the ability to turn off non-repeatable underscores was added.
<p>Integer and Real tokens had an option added to support signed literals.
This option is set <b>on</b> by default (which causes a minor backward
incompatability). Syntaxes that have addition or subtraction operators
will need to turn this option off.
<p>A test to verify proper handling of default parameters was added to
the Test directory. A makefile was also added to the same directory to
facilitate automatic compiling and running of the tests. This makefile
will not work in a non-Gnat/NT environment without some modification.
<p>New recognizers were added for enclosed comments (eg: C's /* */ comments)and&nbsp;
single character escape sequences. Also a "null" recognizer was added for
use as a default token.
<br>&nbsp;
<h3>
Version 1.2.1</h3>
This version adds the CSV field token recognizer that was inadvertently
left out of 1.2. This recognizer was designed to match fields in comma-separated
value (CSV) files, which is a somewhat standard file format for databases
and spreadsheets. Also, the extraneous CVS directories in the zip version
of the distribution were removed.
<h3>
Version 1.2</h3>
The long-awaited string recognizer has been added. It is capable of recognizing
both C and Ada-style strings. In addition, there are a great many submissions
by Christoph Grein in this release. He contributed mostly complete lexical
analyzers for both Java and Ada, along with all the extra token recognizers
he needed to accomplish this feat. He didn't need as many extra recognizers
as I would have thought he'd need. But even so, slightly less than 1/2
of the recognizers in this release were contributed by Chris (with a broken
arm, no less!)
<h3>
Version 1.1</h3>
The main code change to this version is a default text feeder function
that has been added to the analyzer. It reads its input from Ada.Text_IO.Current_Input,
so you can change the file to whatever you want fairly easily. The capability
to create and use your own feeder function still exists, but it should
not be necessary in most cases. If you already have code that does this,
it should still compile and work properly.
<p>The other addition is the first version of the OpenToken user's guide.
All it contains right now is a user manual walking through the steps needed
to make a simple token analyzer. Feedback and/or ideas on this are welcome.
<h3>
Version 1.0</h3>
This is the very first publicly released version. This package is based
on work I did while working on the JPATS trainer for FlightSafety International.
The germ of this idea came while I was trying to port a fairly ambitious,
but fatally buggy Ada 83 token recognition package written for a previous
simulator. But once I was done, I was rather suprised at the flexibility
of the final product. Seeing the possible benefit to the community, and
to the company through user-submitted enhancement and debugging, I suggested
that this code be released as Open Source. They were open-minded enough
to agree. Bravo!
<br>&nbsp;
<h2>
Future</h2>
As it stands, I am developing and maintaining this package as part of my
master's thesis. Thus you can count on a certain amount of progress in
the next few months
<p>Things on my plate for the next release:
<ul>
<li>
More functionality out of the lalr parser. Possiblities include</li>

<ul>
<li>
Better support for ambigouos grammars.</li>

<li>
More intelligent error reporting and handling</li>

<li>
The ability to specify your own error routines for specific parse table
entries.</li>
</ul>

<li>
A Reference Manual describing all the routines in all the packages</li>

<li>
A reference manual generator (with which the above will be created)</li>

<li>
Inclusion of the Modula-3 analyzer submitted by David Starner</li>
</ul>
Things you can help with:
<ul>
<li>
More recognizers - The more of these there are, the more useful this facility
is. If you make 'em, please send 'em in!</li>

<li>
Generally usable Tokens - I'm not sure there are as many reusable tokens
out there as there are reusable recognizers, but I await pleasent suprises.</li>

<li>
Useful token support packages. One example would be a generic symbol table
creation/lookup package.</li>

<li>
New parser generators. These aren't tirvial to build, but if you make youself
an Cannonical LR parser or somesuch, I'd we'd love to have it.</li>

<li>
Well isolated bug reports (or even fixes). Version 2.0 has quite a few
changes, so bugs are much more likely in this version.</li>
</ul>
Again, I hope you find this package useful for your needs.
<p>T.E.D.&nbsp; - <a href="mailto:dennison@telepath.com">dennison@telepath.com</a>
</body>
</html>
